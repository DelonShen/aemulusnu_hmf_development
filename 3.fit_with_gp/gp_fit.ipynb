{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "275029f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "368a58a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from scipy.integrate import quad, fixed_quad\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "import functools\n",
    "import sys\n",
    "from tqdm import tqdm, trange\n",
    "from aemulusnu_hmf.utils import *\n",
    "from aemulusnu_massfunction.emulator_training import *\n",
    "\n",
    "from classy import Class\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f7577c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaving out Box65_1400\n"
     ]
    }
   ],
   "source": [
    "leave_out_box = 'Box89_1400'\n",
    "leave_out_box = 'Box65_1400'\n",
    "\n",
    "\n",
    "# leave_out_box = 'Box_n50_23_1400'\n",
    "# leave_out_box = 'Box_n50_28_1400'\n",
    "# leave_out_box = 'Box69_1400'\n",
    "# leave_out_box = 'Box_n50_39_1400'\n",
    "# leave_out_box = 'Box_n50_23_1400'\n",
    "# leave_out_box = 'Box_n50_19_1400'\n",
    "\n",
    "print('Leaving out', leave_out_box)\n",
    "\n",
    "cosmos_f = open('../data/cosmo_params.pkl', 'rb')\n",
    "cosmo_params = pickle.load(cosmos_f) #cosmo_params is a dict\n",
    "cosmos_f.close()\n",
    "\n",
    "a_list_fname = '/oak/stanford/orgs/kipac/users/delon/aemulusnu_massfunction/alist.pkl'\n",
    "a_list_f = open(a_list_fname, 'rb')\n",
    "a_list = pickle.load(a_list_f)\n",
    "a_list_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36bdedca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:00<00:00, 2372.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ns': 0.97000003, 'H0': 67.0, 'w0': -1.0, 'ombh2': 0.0223, 'omch2': 0.12, 'nu_mass_ev': 0.07071068, '10^9 As': 2.10100315}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "weird_boxes = []\n",
    "\n",
    "\n",
    "errors = {a:{} for a in a_list}\n",
    "X = []\n",
    "Y = []\n",
    "Xlo = []\n",
    "Ylo = []\n",
    "z_to_a = {}\n",
    "a_to_z = {}\n",
    "kt = np.logspace(-3, 1, 100) # h/Mpc\n",
    "for box in tqdm(cosmo_params):\n",
    "    if(box in weird_boxes):\n",
    "        continue\n",
    "    curr_cosmo = cosmo_params[box]\n",
    "    if(box == 'Box_n50_0_1400'):\n",
    "        print(curr_cosmo)\n",
    "\n",
    "    curr_cosmo_values = [curr_cosmo[curr_key] for curr_key in key_ordering]\n",
    "\n",
    "    h = curr_cosmo['H0']/100\n",
    "\n",
    "    Ωb =  curr_cosmo['ombh2'] / h**2\n",
    "    Ωc =  curr_cosmo['omch2'] / h**2\n",
    "\n",
    "    try:\n",
    "        with open(\"/oak/stanford/orgs/kipac/users/delon/aemulusnu_massfunction/%s_params.pkl\"%(box), \"rb\") as f:\n",
    "            MLE_params = pickle.load(f)\n",
    "            param_values = list(MLE_params.values())\n",
    "            if(leave_out_box == box):\n",
    "                Xlo += [curr_cosmo_values]\n",
    "                Ylo += [param_values]\n",
    "            else:\n",
    "                Y+= [param_values]\n",
    "                X+= [curr_cosmo_values]\n",
    "    except:\n",
    "        print(box, z)\n",
    "    for a in a_list:\n",
    "        z = scaleToRedshift(a)\n",
    "        z_to_a[z] = a\n",
    "        a_to_z[a] = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dc0ffbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149, 7)\n",
      "(149, 8)\n",
      "scaling input\n",
      "(149, 7)\n",
      "scaling output\n",
      "(149, 8)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "Xlo = np.array(Xlo)\n",
    "Ylo = np.array(Ylo)\n",
    "# print(Xlo)\n",
    "# print(Ylo)\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "################################\n",
    "print('scaling input')\n",
    "in_scaler = Normalizer()\n",
    "in_scaler.fit(X)\n",
    "X = in_scaler.transform(X)\n",
    "Xlo = in_scaler.transform(Xlo)\n",
    "print(X.shape)\n",
    "\n",
    "\n",
    "print('scaling output')\n",
    "out_scaler = Identity()\n",
    "out_scaler.fit(Y)\n",
    "Y = out_scaler.transform(Y)\n",
    "print(Y.shape)\n",
    "\n",
    "##REMEMBER TO UNSCALE OUTPUT AND SAVE SCALERS#####\n",
    "\n",
    "X_train = torch.from_numpy(X).float()\n",
    "Y_train = torch.from_numpy(Y).float()\n",
    "n_tasks = len(Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69135b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=n_tasks,\n",
    "                                                              has_global_noise=True, \n",
    "                                                              has_task_noise=False,\n",
    "                                                              noise_constraint=gpytorch.constraints.LessThan(1e-8)\n",
    "                                                             )\n",
    "likelihood.noise = 1e-8  # Some small value, but don't make it too small or numerical performance will suffer. I recommend 1e-4.\n",
    "likelihood.raw_noise.requires_grad_(False)  # Mark that we don't want to train the noise.\n",
    "\n",
    "\n",
    "model = MultitaskGPModel(X_train, Y_train, likelihood)\n",
    "\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "\n",
    "training_iterations = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eb178a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   0%|          | 3/1000 [00:09<50:09,  3.02s/it, loss=0.445]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12673/2728292485.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mepochs_iter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/gpytorch/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDistribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinearOperator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_validate_module_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/gpytorch/mlls/exact_marginal_log_likelihood.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, function_dist, target, *params, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;31m# Get the log prob of the marginal distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_other_terms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/gpytorch/distributions/multitask_multivariate_normal.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mnew_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/gpytorch/distributions/multivariate_normal.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;31m# Get log determininant and first part of quadratic form\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mcovar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0minv_quad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv_quad_logdet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minv_quad_rhs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minv_quad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/linear_operator/operators/kronecker_product_added_diag_linear_operator.py\u001b[0m in \u001b[0;36minv_quad_logdet\u001b[0;34m(self, inv_quad_rhs, logdet, reduce_inv_quad)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0minv_quad_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mlogdet_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logdet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlogdet\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minv_quad_term\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet_term\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/linear_operator/operators/kronecker_product_added_diag_linear_operator.py\u001b[0m in \u001b[0;36m_logdet\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_diag_is_constant\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;31m# symeig requires computing the eigenvectors for it to be differentiable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_symeig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meigenvectors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0mevals_plus_diag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevals\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_diagonal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals_plus_diag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/linear_operator/operators/kronecker_product_linear_operator.py\u001b[0m in \u001b[0;36m_symeig\u001b[0;34m(self, eigenvectors, return_evals_as_lazy)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_ops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m             \u001b[0mevals_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevecs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_symeig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meigenvectors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meigenvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m             \u001b[0mevals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0mevecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevecs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/linear_operator/operators/_linear_operator.py\u001b[0m in \u001b[0;36m_symeig\u001b[0;34m(self, eigenvectors, return_evals_as_lazy)\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;31m# potentially perform decomposition in double precision for numerical stability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 886\u001b[0;31m         \u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meigh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_linalg_dtype_symeig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m         \u001b[0;31m# chop any negative eigenvalues.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;31m# TODO: warn if evals are significantly negative\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs_iter = tqdm(range(training_iterations), desc=\"Iteration\")\n",
    "\n",
    "\n",
    "# Create the optimizer with the initial learning rate\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.01, amsgrad=True)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "for i in epochs_iter:\n",
    "    # Training step\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X_train)\n",
    "    loss = -mll(output, Y_train)\n",
    "    epochs_iter.set_postfix(loss=loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "#     print('Iter %d/%d - Loss: %.4f' % (i + 1, training_iterations, loss.item()))\n",
    "\n",
    "#     if i == 100:\n",
    "#         lr = 0.01\n",
    "#         print('reducing lr to %f'%lr)\n",
    "#         for param_group in optimizer.param_groups:\n",
    "#             param_group['lr'] = lr\n",
    "\n",
    "    if i == 500:\n",
    "        lr = 0.001\n",
    "        print('reducing lr to %f'%lr)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "    if i == 1000:\n",
    "        lr = 0.0001\n",
    "        print('reducing lr to %f'%lr)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad4f32b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69546e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"/oak/stanford/orgs/kipac/users/delon/aemulusnu_massfunction/GP_lo%s.pkl\"%(leave_out_box), \"wb\") as f:\n",
    "    pickle.dump([model,\n",
    "                in_scaler,\n",
    "                out_scaler,\n",
    "                likelihood,], f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adff4944",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Emulator = MassFuncAemulusNu_GP_emulator_training(emulator_loc = \"/oak/stanford/orgs/kipac/users/delon/aemulusnu_massfunction/GP_lo%s.pkl\"%(leave_out_box))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f456ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "box =leave_out_box\n",
    "\n",
    "NvM_fname = '/oak/stanford/orgs/kipac/users/delon/aemulusnu_massfunction/'+box+'_NvsM.pkl'\n",
    "NvM_f = open(NvM_fname, 'rb')\n",
    "NvMs = pickle.load(NvM_f) #NvMs is a dictionary of dictionaries\n",
    "NvM_f.close()\n",
    "\n",
    "N_data = {}\n",
    "M_data = {}\n",
    "aux_data = {}\n",
    "\n",
    "vol = -1 #Mpc^3/h^3\n",
    "Mpart = -1\n",
    "\n",
    "for a in tqdm(a_list):\n",
    "#     if(a != 1): #TEST\n",
    "#         continue\n",
    "    c_data = NvMs[a]\n",
    "\n",
    "    Ms = c_data['M'] #units of h^-1 Msolar\n",
    "    N = c_data['N']\n",
    "    edge_pairs = c_data['edge_pairs']\n",
    "    assert(len(Ms) == len(edge_pairs))\n",
    "    assert(len(Ms) == len(N))\n",
    "\n",
    "    if(vol==-1):\n",
    "        vol = c_data['vol']\n",
    "    assert(vol == c_data['vol'])\n",
    "\n",
    "    if(Mpart==-1):\n",
    "        Mpart = c_data['Mpart']\n",
    "    assert(Mpart == c_data['Mpart'])\n",
    "\n",
    "    N_data[a] = []\n",
    "    M_data[a] = []\n",
    "    aux_data[a] = []\n",
    "    for N_curr, M_curr, edge_pair in zip(N, Ms, edge_pairs):\n",
    "        N_data[a] += [N_curr]\n",
    "        M_data[a] += [M_curr]\n",
    "        aux_data[a] += [{'a':a, 'edge_pair':edge_pair}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec66cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aemulusnu_hmf import massfunction as hmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee53fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_numerics = np.logspace(np.log10(100*Mpart), 16, 50)\n",
    "\n",
    "jackknife_covs_fname = '/oak/stanford/orgs/kipac/users/delon/aemulusnu_massfunction/'+box+'_jackknife_covs.pkl'\n",
    "jackknife_covs_f = open(jackknife_covs_fname, 'rb')\n",
    "jackknife = pickle.load(jackknife_covs_f)\n",
    "jackknife_covs_f.close()\n",
    "\n",
    "jack_covs = {a:jackknife[a][1] for a in N_data}\n",
    "\n",
    "# Compute the weighted covariance matrix incorporating jackknife and poisson\n",
    "weighted_cov = {a: jack_covs[a] for a in jack_covs}\n",
    "\n",
    "param_names = ['d','e','f','g']\n",
    "\n",
    "\n",
    "true_params = {}\n",
    "for c_X, c_Y, a in zip(Xlo, Ylo, a_list):\n",
    "    true_params[a] = c_Y\n",
    "\n",
    "cosmology = hmf.cosmology(cosmo_params[leave_out_box])\n",
    "\n",
    "h = cosmo_params[leave_out_box]['H0']/100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbe7bc0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(ncols=1, nrows=4, figsize=(10,15), sharex=True)\n",
    "wjat = [leave_out_box, 'Box_n50_0_1400', 'Box_n50_14_1400', 'Box_n50_33_1400', 'Box_n50_32_1400']\n",
    "# wjat = [leave_out_box, 'Box26_1400']\n",
    "wjat = [leave_out_box]\n",
    "# for box in [leave_out_box]:#, 'Box_n50_14_1400']:\n",
    "# for box in [leave_out_box, 'Box98_1400', 'Box_n50_0_1400']:#, 'Box_n50_14_1400', 'Box_n50_33_1400', 'Box_n50_32_1400']:\n",
    "for box in tqdm(wjat):\n",
    "    curr_cosmo_vals = tuple(get_cosmo_vals(cosmo_params[box]))\n",
    "\n",
    "    param_names = ['d','e','f','g']\n",
    "    ndim = len(param_names)\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "    params = {'d':[], 'e':[], 'f':[], 'g':[]}\n",
    "    paramsEMU = {'d':[], 'e':[], 'f':[], 'g':[]}\n",
    "\n",
    "    for a in a_list:\n",
    "        R = 8 / (cosmo_params[box]['H0'] / 100)\n",
    "        EMU  = (Emulator.predict_params(cosmology, scaleToRedshift(a))) #, sigma8z))\n",
    "\n",
    "        with open(\"/oak/stanford/orgs/kipac/users/delon/aemulusnu_massfunction/%s_params.pkl\"%(box), \"rb\") as f:\n",
    "            MLE_params = pickle.load(f)\n",
    "            curr_params = list(MLE_params.values())\n",
    "            paired_params = list(zip(curr_params, curr_params[1:]))[::2]\n",
    "\n",
    "            param_at_z = {'d':-1, 'e':-1, 'f':-1, 'g':-1}\n",
    "\n",
    "            for (p0,p1), key in zip(paired_params, param_at_z):\n",
    "                param_at_z[key] = p(p0, p1, a)\n",
    "            MLE_params = param_at_z\n",
    "            \n",
    "        for key in MLE_params:\n",
    "#             print(key)\n",
    "            params[key] += [MLE_params[key]]\n",
    "#             print(EMU)\n",
    "            paramsEMU[key] += [EMU[key]]\n",
    "\n",
    "\n",
    "    for i, param in enumerate(params):\n",
    "        aaaaa = 1\n",
    "        if(box != leave_out_box):\n",
    "            aaaaa = 0.1\n",
    "        axs[i].scatter(a_list, params[param], alpha=aaaaa, color='blue')\n",
    "#         print(list(zip(a_list,params[param])))\n",
    "#         print()\n",
    "        axs[i].plot(a_list, params[param], alpha=aaaaa, color='blue')\n",
    "\n",
    "        axs[i].scatter(a_list, paramsEMU[param], alpha=aaaaa, color='red')\n",
    "        axs[i].plot(a_list, paramsEMU[param], alpha=aaaaa, color='red')\n",
    "\n",
    "        axs[i].set_ylabel(param)\n",
    "    #     axs[i].set_ylim([0,2])\n",
    "        axs[i].set_xlim([min(a_list), 1])\n",
    "\n",
    "axs[-1].set_xlabel('a')\n",
    "# axs[0].set_ylim([0.25,.45])\n",
    "# axs[1].set_ylim([0.29,.305])\n",
    "# axs[2].set_ylim([1.4,1.8])\n",
    "# axs[3].set_ylim([1.18, 1.2])\n",
    "axs[0].set_ylim([1.7, 3.])\n",
    "axs[1].set_ylim([0.9, 1.2])\n",
    "axs[2].set_ylim([.3,.6])\n",
    "# axs[3].set_ylim([1.15,1.25])\n",
    "# axs[0].set_title(box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb17df98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60821fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d725c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140966d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLE_params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88faa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "box = leave_out_box\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5a12b2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for a in tqdm(a_list):\n",
    "    yerr = np.sqrt(np.diagonal(weighted_cov[a]))\n",
    "    fig1 = plt.figure(figsize =(12, 7))\n",
    "\n",
    "    axs=[fig1.add_axes((0.0,0.4,1,.6)), fig1.add_axes((0.0,0.0,1,.4))]\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    c_data = NvMs[a]\n",
    "\n",
    "    Ms = M_data[a]\n",
    "    N = N_data[a]\n",
    "    edge_pairs = c_data['edge_pairs']\n",
    "\n",
    "    edges = [edge[0] for edge in edge_pairs]\n",
    "    edges += [edge_pairs[-1][1]]\n",
    "\n",
    "    #shade in 1% and 10% error region\n",
    "    edges = np.array(edges)\n",
    "    \n",
    "    \n",
    "\n",
    "    y1 = 0.1*np.ones_like(N)\n",
    "    y1 = np.append(y1, y1[-1])\n",
    "    y1 = np.append(y1[0], y1)\n",
    "\n",
    "    y2 = -0.1*np.ones_like(N)\n",
    "    y2 = np.append(y2, y2[-1])\n",
    "    y2 = np.append(y2[0], y2)\n",
    "\n",
    "    c_Ms = np.append(Ms, edges[-1])\n",
    "    c_Ms = np.append(edges[0], c_Ms)\n",
    "    axs[1].fill_between(c_Ms, y1, y2, alpha=1, color='0.95',label='<10% Error')\n",
    "\n",
    "    y1 = 0.01*np.ones_like(N)\n",
    "    y1 = np.append(y1, y1[-1])\n",
    "    y1 = np.append(y1[0], y1)\n",
    "\n",
    "    y2 = -0.01*np.ones_like(N)\n",
    "    y2 = np.append(y2, y2[-1])\n",
    "    y2 = np.append(y2[0], y2)\n",
    "\n",
    "    axs[1].fill_between(c_Ms, y1, y2, alpha=1, color='0.85',label='<1% Error')\n",
    "\n",
    "\n",
    "    dM = np.array([edges[1]-edges[0] for edges in edge_pairs])\n",
    "\n",
    "\n",
    "    #Emulator \n",
    "    f_dNdM_MCMC =  lambda M:Emulator(cosmology, M, a)*vol# h / Msun\n",
    "    tinker_eval_MCMC = np.array([quad(f_dNdM_MCMC, edge[0],  edge[1], epsabs=0, epsrel=1e-5)[0] for edge in edge_pairs])\n",
    "\n",
    "    axs[0].scatter(Ms, tinker_eval_MCMC, marker='x', c='red')\n",
    "    axs[0].bar(x=edges[:-1], height=tinker_eval_MCMC, width=np.diff(edges),\n",
    "               align='edge', fill=False, ec='red', label='Emulator')\n",
    "#     with open(\"/oak/stanford/orgs/kipac/users/delon/aemulusnu_massfunction/%s_%.2f_NvMemulator_loo_output.pkl\"%(box, a), \"wb\") as f:\n",
    "#         pickle.dump({'Ms':Ms, 'tinker_eval':tinker_eval_MCMC, 'N':N, 'edges':edges}, f)\n",
    "\n",
    "    tmp = np.array([c_tmp*10**(0.01)-c_tmp for c_tmp in Ms])\n",
    "    axs[1].errorbar(Ms + tmp, (tinker_eval_MCMC-N)/N, yerr/N, fmt='x', color='red')\n",
    "\n",
    "    #ML Fit\n",
    "\n",
    "    mass_function = MassFuncAemulusNu_fitting_all_snapshot()\n",
    "    \n",
    "    with open(\"/oak/stanford/orgs/kipac/users/delon/aemulusnu_massfunction/%s_params.pkl\"%(box), \"rb\") as f:\n",
    "        MLE_params = pickle.load(f)\n",
    "#         print(list(MLE_params.values()))\n",
    "        mass_function.set_params(list(MLE_params.values()))\n",
    "\n",
    "\n",
    "    f_dNdM_MCMC =  lambda M:mass_function(cosmology, M, a)*vol # h / Msun\n",
    "    tinker_eval_MCMC = np.array([quad(f_dNdM_MCMC, edge[0],  edge[1], epsabs=0, epsrel=1e-5)[0] for edge in edge_pairs])\n",
    "    axs[0].scatter(Ms, tinker_eval_MCMC, s=50 , marker='x', c='blue')\n",
    "    axs[0].bar(x=edges[:-1], height=tinker_eval_MCMC, width=np.diff(edges), \n",
    "               align='edge', fill=False, ec='blue', label='ML Fit')\n",
    "    axs[1].errorbar(Ms, (tinker_eval_MCMC-N)/N, yerr/N, fmt='x', color='blue')\n",
    "\n",
    "\n",
    "\n",
    "    #Data\n",
    "    axs[0].bar(x=edges[:-1], height=N, width=np.diff(edges),\n",
    "           align='edge', fill=False, ec='black', label='Data')\n",
    "    axs[0].errorbar(Ms, N, yerr, fmt='+', c='black')\n",
    "\n",
    "    axs[0].set_xscale('log')\n",
    "    axs[0].set_yscale('log')\n",
    "    axs[0].legend(frameon=False)\n",
    "    axs[0].set_ylabel('N')\n",
    "\n",
    "    axs[1].set_xscale('log')\n",
    "    # axs[1].set_yscale('lin', linthresh=1e-2)    \n",
    "    axs[1].legend(frameon=False)\n",
    "    axs[1].axhline(0, c='black')\n",
    "    axs[1].set_ylabel('N')\n",
    "    axs[1].set_xlabel(r'Mass $[h^{-1}M_\\odot]$')\n",
    "    axs[1].set_ylabel(r'$\\frac{N_{\\rm emulator}-N_{\\rm data}}{N_{\\rm data}} $')\n",
    "    axs[0].set_title('%s, a=%.2f, z=%.2f'%(box, a, scaleToRedshift(a)))\n",
    "\n",
    "    left = np.ceil(np.log10(200*Mpart) * 10) / 10\n",
    "    axs[0].set_xlim((10**left, np.max(edges)))\n",
    "    axs[1].set_xlim((10**left, np.max(edges)))\n",
    "    axs[1].set_ylim((-.29, .29))\n",
    "    axs[1].set_yticks([-.2, -.1, 0, .1, .2])\n",
    "\n",
    "#     plt.savefig('/oak/stanford/orgs/kipac/users/delon/aemulusnu_massfunction/figures/emulator/%s_emufit_%.2f.pdf'%(box, a), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf6cd0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4f8189",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "massfunction",
   "language": "python",
   "name": "massfunction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
