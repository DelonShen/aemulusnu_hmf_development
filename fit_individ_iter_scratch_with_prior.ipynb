{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "106e0bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "box = 'Box_n50_0_1400'\n",
    "param_names = ['d','e','f','g']\n",
    "ndim = len(param_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be3a0805",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from massfunction import *\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import emcee\n",
    "import sys\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "770b825b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmos_f = open('data/cosmo_params.pkl', 'rb')\n",
    "cosmo_params = pickle.load(cosmos_f) #cosmo_params is a dict\n",
    "cosmos_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5637a802",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmo = cosmo_params[box]\n",
    "mass_function = MassFunction(cosmo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a34f6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = cosmo['H0']/100\n",
    "\n",
    "NvM_fname = '/oak/stanford/orgs/kipac/users/delon/aemulusnu_massfunction/'+box+'_NvsM.pkl'\n",
    "NvM_f = open(NvM_fname, 'rb')\n",
    "NvMs = pickle.load(NvM_f) #NvMs is a dictionary of dictionaries\n",
    "NvM_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "001d46b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25, 0.302679, 0.366459, 0.403224, 0.488191, 0.512095, 0.537169, 0.563471, 0.591061, 0.620002, 0.65036, 0.715608, 0.787402, 0.866399, 0.953321, 1.0]\n",
      "[3.0, 2.3038301302700224, 1.7288182306888356, 1.4800111104497748, 1.0483786059144884, 0.9527626709887815, 0.8616115226306804, 0.7747142266416549, 0.691872750866662, 0.6128980229096033, 0.5376099391106464, 0.3974131088528914, 0.26999931420037027, 0.15420262488760939, 0.04896461947234987, 0.0]\n"
     ]
    }
   ],
   "source": [
    "all_as = list(NvMs.keys())\n",
    "all_zs = list(map(scaleToRedshift, all_as))\n",
    "print(all_as)\n",
    "print(all_zs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "348f5523",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]/home/users/delon/aemulusnu_massfunction/utils.py:36: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "  res, err = quad(dσ2dk, 0, np.inf)\n",
      "/home/users/delon/aemulusnu_massfunction/utils.py:60: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "  res, err = quad(dσ2dRdk, 0, np.inf)\n",
      "100%|██████████| 16/16 [01:18<00:00,  4.92s/it]\n"
     ]
    }
   ],
   "source": [
    "N_data = {}\n",
    "M_data = {}\n",
    "aux_data = {}\n",
    "from scipy.interpolate import interp1d, UnivariateSpline, InterpolatedUnivariateSpline\n",
    "\n",
    "\n",
    "vol = -1 #Mpc^3/h^3\n",
    "Mpart = -1\n",
    "\n",
    "for a in tqdm(all_as):\n",
    "    c_data = NvMs[a]\n",
    "    \n",
    "    Ms = c_data['M'] #units of h^-1 Msolar\n",
    "    N = c_data['N']\n",
    "    edge_pairs = c_data['edge_pairs']\n",
    "    assert(len(Ms) == len(edge_pairs))\n",
    "    assert(len(Ms) == len(N))\n",
    "    \n",
    "\n",
    "    if(vol==-1):\n",
    "        vol = c_data['vol']\n",
    "    assert(vol == c_data['vol'])\n",
    "\n",
    "    if(Mpart==-1):\n",
    "        Mpart = c_data['Mpart']\n",
    "    assert(Mpart == c_data['Mpart'])\n",
    "\n",
    "    N_data[a] = []\n",
    "    M_data[a] = []\n",
    "    aux_data[a] = []\n",
    "    for N_curr, M_curr, edge_pair in zip(N, Ms, edge_pairs):\n",
    "        N_data[a] += [N_curr]\n",
    "        M_data[a] += [M_curr]\n",
    "        aux_data[a] += [{'a':a, 'edge_pair':edge_pair}]\n",
    "    \n",
    "    mass_function.compute_dlnsinvdM(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "267099bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_list = list(NvMs.keys())\n",
    "\n",
    "from scipy.stats import poisson\n",
    "\n",
    "\n",
    "M_numerics = np.logspace(np.log10(100*Mpart), 17, 50)\n",
    "\n",
    "jackknife_covs_fname = '/oak/stanford/orgs/kipac/users/delon/aemulusnu_massfunction/'+box+'_jackknife_covs.pkl'\n",
    "jackknife_covs_f = open(jackknife_covs_fname, 'rb')\n",
    "jackknife = pickle.load(jackknife_covs_f)\n",
    "jackknife_covs_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afb0bba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "jack_covs = {a:jackknife[a][1] for a in N_data}\n",
    "\n",
    "# Compute the weighted covariance matrix incorporating jackknife and poisson\n",
    "weighted_cov = {a: jack_covs[a] for a in jack_covs}\n",
    "\n",
    "# Inverse of the weighted covariance matrix\n",
    "inv_weighted_cov = {a:np.linalg.inv(weighted_cov[a]) for a in weighted_cov}  \n",
    "\n",
    "scale_cov = {a:np.log(np.linalg.det(weighted_cov[a])) for a in weighted_cov}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "457bde87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_log_prior(param_values):\n",
    "    #uniform prior\n",
    "    for param in param_values:\n",
    "        if(param < 0 or param > 5):\n",
    "            return -np.inf\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "539b67f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prob(param_values):   \n",
    "    \"\"\"\n",
    "    Calculates the probability of the given tinker parameters \n",
    "    \n",
    "    Args:\n",
    "        param_values (np.ndarray): Input array of shape (number of params).\n",
    "        \n",
    "    Returns:\n",
    "        float: Resulting log probability\n",
    "    \"\"\"\n",
    "\n",
    "    if(uniform_log_prior(param_values) == -np.inf):\n",
    "        return -np.inf\n",
    "\n",
    "    params = dict(zip(param_names, param_values))\n",
    "\n",
    "    tinker_fs = {}\n",
    "    \n",
    "    for a in N_data:\n",
    "        tinker_eval = [mass_function.tinker(a, M_c, **params)*vol for M_c in M_numerics]\n",
    "        f_dndlogM = interp1d(M_numerics, tinker_eval, kind='linear', bounds_error=False, fill_value=0.)\n",
    "        tinker_fs[a] = f_dndlogM\n",
    "        \n",
    "    model_vals = {}\n",
    "    for a in N_data:\n",
    "        if(scaleToRedshift(a) >=2):\n",
    "            continue\n",
    "        model_vals[a] = np.array([quad(tinker_fs[a], edge_pair[0], edge_pair[1], epsabs=1e-1)[0]\n",
    "            for edge_pair in NvMs[a]['edge_pairs']\n",
    "        ])\n",
    "    \n",
    "    \n",
    "    residuals = {a: model_vals[a]-N_data[a] for a in model_vals}\n",
    "    log_probs = [ -0.5 * (len(inv_weighted_cov)* np.log(2*np.pi) + \n",
    "                          np.dot(np.dot(residuals[a].T, inv_weighted_cov[a]), residuals[a]) + \n",
    "                          scale_cov[a]) \n",
    "                 for a in model_vals]\n",
    "    if not np.isfinite(np.sum(log_probs)): \n",
    "        return -np.inf\n",
    "    return np.sum(log_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd388f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(param_values):\n",
    "    lp = uniform_log_prior(param_values)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + log_prob(param_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bfaefa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_sampler = None\n",
    "with open(\"/oak/stanford/orgs/kipac/users/delon/aemulusnu_massfunction/%s_%.2f_MCMC_sampler.pkl\"%(box, 1.0), \"rb\") as f:\n",
    "    prev_sampler = pickle.load(f)\n",
    "samples = prev_sampler.chain[:, 500:, :].reshape((-1, ndim))\n",
    "prev_final_param_vals = np.percentile(samples,  50,axis=0)\n",
    "\n",
    "tot_params = {1.0: prev_final_param_vals}\n",
    "\n",
    "PARAM_SPREAD = 0.001\n",
    "KX = np.diag([PARAM_SPREAD for _ in range(ndim)])\n",
    "KXinv = np.linalg.inv(KX)\n",
    "detKX = np.linalg.det(KX)\n",
    "logdetKX = np.log(detKX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f22ee430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prior(param_values):\n",
    "    \n",
    "    xmp = param_values - prev_final_param_vals\n",
    "    arg = np.dot(np.dot(xmp.T, KXinv), xmp)\n",
    "    return -1/2*(ndim * np.log(2*np.pi) + logdetKX + arg)\n",
    "def log_likelihood_with_prior(param_values):\n",
    "    lp = log_prior(param_values)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + log_prob(param_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b9caa7",
   "metadata": {},
   "source": [
    "We'll use the parameters obtained for previous redshift as prior for current redshift. Let $p$ be the previous parameters and $n$ be the number of parameters. The prior is then \n",
    "$$P(x) = \\frac 1 {\\left[(2 \\pi)^{n} {\\rm det}K_x\\right]^{1/2}}\\times {\\rm exp} \\left\\{-\\frac 1 2 (x-p)\\cdot K_x^{-1} \\cdot (x-p) \\right\\} $$\n",
    "$$\\Rightarrow \\log P(x) = -\\frac 1 2 \\left(\\ln {\\rm det} K_x  + (x-p)\\cdot K_x^{-1}\\cdot (x-p)\\right)$$\n",
    "We will set $K_X$ by hand as $K_X={\\rm diag}(0.1, 0.1, 0.1, 0.1)$ (pulled out of a hat but roughly seems appropriate to assert smooth varying as function of redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a23cdbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prev_sampler = None\n",
    "# with open(\"/oak/stanford/orgs/kipac/users/delon/aemulusnu_massfunction/%s_%.2f_MCMC_sampler.pkl\"%(prev_box, prev_a), \"rb\") as f:\n",
    "#     prev_sampler = pickle.load(f)\n",
    "# samples = prev_sampler.chain[:, 500:, :].reshape((-1, ndim))\n",
    "# prev_final_param_vals = np.percentile(samples,  50,axis=0)\n",
    "# prev_params_final = dict(zip(param_names, prev_final_param_vals))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45bc3c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.953321,\n",
       " 0.866399,\n",
       " 0.787402,\n",
       " 0.715608,\n",
       " 0.65036,\n",
       " 0.620002,\n",
       " 0.591061,\n",
       " 0.563471,\n",
       " 0.537169,\n",
       " 0.512095,\n",
       " 0.488191,\n",
       " 0.403224,\n",
       " 0.366459,\n",
       " 0.302679,\n",
       " 0.25]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f66557b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.54353975 1.11303385 2.46444467 1.32940968]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [00:01<00:17,  1.25s/it]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0.953321",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19396/1812868522.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_as\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0ma_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_as\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprev_final_param_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtot_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mall_as\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     guess = prev_final_param_vals + np.random.normal(loc=0, \n\u001b[1;32m      5\u001b[0m                                                  \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPARAM_SPREAD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0.953321"
     ]
    }
   ],
   "source": [
    "for i in trange(1, len(all_as)):\n",
    "    a_fit = all_as[::-1][i]    \n",
    "    prev_final_param_vals = tot_params[all_as[::-1][i-1]]\n",
    "    guess = prev_final_param_vals + np.random.normal(loc=0, \n",
    "                                                 scale=PARAM_SPREAD, \n",
    "                                                 size=prev_final_param_vals.shape)\n",
    "    while(not np.isfinite(log_likelihood_with_prior(guess))):\n",
    "        guess = prev_final_param_vals + np.random.normal(loc=0, \n",
    "                                                         scale=PARAM_SPREAD, \n",
    "                                                         size=prev_final_param_vals.shape)\n",
    "    print('Starting ML Fit')\n",
    "    #Start by sampling with a maximum likelihood approach\n",
    "    from scipy import optimize as optimize\n",
    "    nll = lambda *args: -log_likelihood_with_prior(*args)\n",
    "    result = optimize.minimize(nll, guess, method=\"Nelder-Mead\", options={\n",
    "        'maxiter': len(guess)*10000\n",
    "    })\n",
    "    result['param_names'] = param_names\n",
    "    print(box)\n",
    "    print(result)\n",
    "    print(result['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16676cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6164da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(log_likelihood_with_prior(prev_final_param_vals), log_prior(prev_final_param_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e499292",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(log_likelihood_with_prior(result['x']), log_prior(result['x']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59060dd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5262a4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLE_params = dict(zip(param_names, result['x']))\n",
    "print(MLE_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356a2f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_params_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a1686c",
   "metadata": {},
   "outputs": [],
   "source": [
    "yerr_dict = {a:np.sqrt(np.diagonal(weighted_cov[a])) for a in weighted_cov} \n",
    "c_params = MLE_params\n",
    "a = a_fit\n",
    "\n",
    "fig1 = plt.figure(figsize =(12, 7))\n",
    "\n",
    "axs=[fig1.add_axes((0.0,0.4,1,.6)), fig1.add_axes((0.0,0.0,1,.4))]\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "Pk = mass_function.Pka[a]\n",
    "c_data = NvMs[a]\n",
    "\n",
    "Ms = M_data[a]\n",
    "N = N_data[a]\n",
    "edge_pairs = c_data['edge_pairs']\n",
    "\n",
    "edges = [edge[0] for edge in edge_pairs]\n",
    "edges += [edge_pairs[-1][1]]\n",
    "\n",
    "yerr = yerr_dict[a]\n",
    "dM = np.array([edges[1]-edges[0] for edges in edge_pairs])\n",
    "\n",
    "\n",
    "tinker_eval_MCMC = [mass_function.tinker(a, M_c, **c_params)*vol for M_c in M_numerics]\n",
    "f_dndM_MCMC =  interp1d(M_numerics, tinker_eval_MCMC, kind='linear', bounds_error=False, fill_value=0.)\n",
    "\n",
    "tinker_eval_MCMC = np.array([quad(f_dndM_MCMC, edge[0],  edge[1])[0] for edge in edge_pairs])\n",
    "\n",
    "\n",
    "\n",
    "axs[0].errorbar(Ms, N, yerr, fmt='+', c='black')\n",
    "axs[0].scatter(Ms, tinker_eval_MCMC, s=50 , marker='x', c='blue')\n",
    "\n",
    "edges = np.array(edges)\n",
    "axs[0].bar(x=edges[:-1], height=N, width=np.diff(edges),\n",
    "           align='edge', fill=False, ec='black', label='Data')\n",
    "axs[0].bar(x=edges[:-1], height=tinker_eval_MCMC, width=np.diff(edges), align='edge', fill=False, ec='blue', label='Tinker')\n",
    "axs[1].errorbar(Ms, (tinker_eval_MCMC-N)/N, yerr/N, fmt='x', color='blue')\n",
    "\n",
    "y1 = 0.1*np.ones_like(N)\n",
    "y1 = np.append(y1, y1[-1])\n",
    "y1 = np.append(y1[0], y1)\n",
    "\n",
    "y2 = -0.1*np.ones_like(N)\n",
    "y2 = np.append(y2, y2[-1])\n",
    "y2 = np.append(y2[0], y2)\n",
    "\n",
    "c_Ms = np.append(Ms, edges[-1])\n",
    "c_Ms = np.append(edges[0], c_Ms)\n",
    "axs[1].fill_between(c_Ms, y1, y2, alpha=1, color='0.95',label='<10% Error')\n",
    "\n",
    "y1 = 0.01*np.ones_like(N)\n",
    "y1 = np.append(y1, y1[-1])\n",
    "y1 = np.append(y1[0], y1)\n",
    "\n",
    "y2 = -0.01*np.ones_like(N)\n",
    "y2 = np.append(y2, y2[-1])\n",
    "y2 = np.append(y2[0], y2)\n",
    "\n",
    "axs[1].fill_between(c_Ms, y1, y2, alpha=1, color='0.85',label='<1% Error')\n",
    "\n",
    "\n",
    "axs[0].set_xscale('log')\n",
    "axs[0].set_yscale('log')\n",
    "axs[0].legend(frameon=False)\n",
    "axs[0].set_ylabel('N')\n",
    "\n",
    "axs[1].set_xscale('log')\n",
    "# axs[1].set_yscale('lin', linthresh=1e-2)    \n",
    "axs[1].legend(frameon=False)\n",
    "axs[1].axhline(0, c='black')\n",
    "axs[1].set_ylabel('N')\n",
    "axs[1].set_xlabel(r'Mass $[h^{-1}M_\\odot]$')\n",
    "axs[1].set_ylabel(r'$\\frac{N_{\\rm Tinker}-N_{\\rm data}}{N_{\\rm data}} $')\n",
    "axs[0].set_title('%s, a=%.2f, z=%.2f'%(box, a, scaleToRedshift(a)))\n",
    "\n",
    "axs[0].set_xlim((1e13, np.max(edges)))\n",
    "axs[1].set_xlim((1e13, np.max(edges)))\n",
    "axs[1].set_ylim((-.19, .19))\n",
    "axs[1].set_yticks([-.1, 0, .1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50025675",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwalkers = 64\n",
    "ndim = len(param_names)\n",
    "\n",
    "initialpos = np.array([result['x'] for _ in range(nwalkers)]) + 1e-2 * np.random.normal(size=(nwalkers, ndim))\n",
    "\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "sampler = emcee.EnsembleSampler(\n",
    "    nwalkers = nwalkers,\n",
    "    ndim = ndim,\n",
    "    log_prob_fn = log_likelihood_with_prior,\n",
    "    pool=Pool()\n",
    ")\n",
    "\n",
    "sampler.run_mcmc(initialpos, 1000, progress=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137365dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = param_names\n",
    "\n",
    "import corner\n",
    "samples = sampler.chain[:, 500:, :].reshape((-1, ndim))\n",
    "final_param_vals = np.percentile(samples,  50,axis=0)\n",
    "params_final = dict(zip(param_names, final_param_vals))\n",
    "fig = corner.corner(samples, labels=labels, quantiles=[0.16, 0.5, 0.84],show_titles=True,)\n",
    "\n",
    "# plt.savefig('/oak/stanford/orgs/kipac/users/delon/aemulusnu_massfunction/figures/%s_MCMC_corner.pdf'%(box), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cac80ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = param_names\n",
    "\n",
    "fig, axes = plt.subplots(ndim, figsize=(10, 30), sharex=True)\n",
    "samples = sampler.get_chain()\n",
    "print(np.shape(samples))\n",
    "for i in range(ndim):\n",
    "    ax = axes[i]\n",
    "    ax.plot(samples[:, :, i], \"k\", alpha=0.1)\n",
    "    ax.set_xlim(0, len(samples))\n",
    "    ax.set_ylabel(labels[i])\n",
    "    ax.yaxis.set_label_coords(-0.1, 0.5)\n",
    "    ax.axhline(result['x'][i], color='red')\n",
    "    ax.axhline(final_param_vals[i], color='blue')\n",
    "axes[-1].set_xlabel(\"step number\");\n",
    "\n",
    "# plt.savefig('/oak/stanford/orgs/kipac/users/delon/aemulusnu_massfunction/figures/%s_MCMC_convergence.pdf'%(box), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c44113b",
   "metadata": {},
   "outputs": [],
   "source": [
    "yerr_dict = {a:np.sqrt(np.diagonal(weighted_cov[a])) for a in weighted_cov} \n",
    "c_params = params_final\n",
    "a = a_fit\n",
    "\n",
    "fig1 = plt.figure(figsize =(12, 7))\n",
    "\n",
    "axs=[fig1.add_axes((0.0,0.4,1,.6)), fig1.add_axes((0.0,0.0,1,.4))]\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "Pk = mass_function.Pka[a]\n",
    "c_data = NvMs[a]\n",
    "\n",
    "Ms = M_data[a]\n",
    "N = N_data[a]\n",
    "edge_pairs = c_data['edge_pairs']\n",
    "\n",
    "edges = [edge[0] for edge in edge_pairs]\n",
    "edges += [edge_pairs[-1][1]]\n",
    "\n",
    "yerr = yerr_dict[a]\n",
    "dM = np.array([edges[1]-edges[0] for edges in edge_pairs])\n",
    "\n",
    "\n",
    "tinker_eval_MCMC = [mass_function.tinker(a, M_c, **c_params)*vol for M_c in M_numerics]\n",
    "#             print(tinker_eval_MCMC)\n",
    "\n",
    "#             f_dndM_MCMC_LOG = interp1d(np.log10(M_numerics), tinker_eval_MCMC, kind='linear', bounds_error=False, fill_value=0.)\n",
    "#             f_dndM_MCMC = lambda x:f_dndM_MCMC_LOG(np.log10(x))\n",
    "f_dndM_MCMC =  interp1d(M_numerics, tinker_eval_MCMC, kind='linear', bounds_error=False, fill_value=0.)\n",
    "\n",
    "tinker_eval_MCMC = np.array([quad(f_dndM_MCMC, edge[0],  edge[1])[0] for edge in edge_pairs])\n",
    "\n",
    "\n",
    "\n",
    "axs[0].errorbar(Ms, N, yerr, fmt='+', c='black')\n",
    "axs[0].scatter(Ms, tinker_eval_MCMC, s=50 , marker='x', c='blue')\n",
    "\n",
    "edges = np.array(edges)\n",
    "axs[0].bar(x=edges[:-1], height=N, width=np.diff(edges),\n",
    "           align='edge', fill=False, ec='black', label='Data')\n",
    "axs[0].bar(x=edges[:-1], height=tinker_eval_MCMC, width=np.diff(edges), align='edge', fill=False, ec='blue', label='Tinker')\n",
    "axs[1].errorbar(Ms, (tinker_eval_MCMC-N)/N, yerr/N, fmt='x', color='blue')\n",
    "\n",
    "y1 = 0.1*np.ones_like(N)\n",
    "y1 = np.append(y1, y1[-1])\n",
    "y1 = np.append(y1[0], y1)\n",
    "\n",
    "y2 = -0.1*np.ones_like(N)\n",
    "y2 = np.append(y2, y2[-1])\n",
    "y2 = np.append(y2[0], y2)\n",
    "\n",
    "c_Ms = np.append(Ms, edges[-1])\n",
    "c_Ms = np.append(edges[0], c_Ms)\n",
    "axs[1].fill_between(c_Ms, y1, y2, alpha=1, color='0.95',label='<10% Error')\n",
    "\n",
    "y1 = 0.01*np.ones_like(N)\n",
    "y1 = np.append(y1, y1[-1])\n",
    "y1 = np.append(y1[0], y1)\n",
    "\n",
    "y2 = -0.01*np.ones_like(N)\n",
    "y2 = np.append(y2, y2[-1])\n",
    "y2 = np.append(y2[0], y2)\n",
    "\n",
    "axs[1].fill_between(c_Ms, y1, y2, alpha=1, color='0.85',label='<1% Error')\n",
    "\n",
    "\n",
    "axs[0].set_xscale('log')\n",
    "axs[0].set_yscale('log')\n",
    "axs[0].legend(frameon=False)\n",
    "axs[0].set_ylabel('N')\n",
    "\n",
    "axs[1].set_xscale('log')\n",
    "# axs[1].set_yscale('symlog', linthresh=1e-2)    \n",
    "axs[1].legend(frameon=False)\n",
    "axs[1].axhline(0, c='black')\n",
    "axs[1].set_ylabel('N')\n",
    "axs[1].set_xlabel(r'Mass $[h^{-1}M_\\odot]$')\n",
    "axs[1].set_ylabel(r'$\\frac{N_{\\rm Tinker}-N_{\\rm data}}{N_{\\rm data}} $')\n",
    "axs[0].set_title('%s, a=%.2f, z=%.2f'%(box, a, scaleToRedshift(a)))\n",
    "\n",
    "axs[0].set_xlim((1e13, np.max(edges)))\n",
    "axs[1].set_xlim((1e13, np.max(edges)))\n",
    "axs[1].set_ylim((-.19, .19))\n",
    "axs[1].set_yticks([-.1, 0, .1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e47fc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/oak/stanford/orgs/kipac/users/delon/aemulusnu_massfunction/%s_%.2f_MCMC_sampler.pkl\"%(box, a_fit), \"wb\") as f:\n",
    "    pickle.dump(sampler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1354263",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19396/963728921.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparams_final\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'params_final' is not defined"
     ]
    }
   ],
   "source": [
    "params_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96da74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/oak/stanford/orgs/kipac/users/delon/aemulusnu_massfunction/%s_%.2f_params_final.pkl\"%(box, a_fit), \"wb\") as f:\n",
    "    pickle.dump(params_final, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "massfunction",
   "language": "python",
   "name": "massfunction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
