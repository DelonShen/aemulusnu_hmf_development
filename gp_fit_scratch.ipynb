{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62912dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from scipy.integrate import quad, fixed_quad\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle \n",
    "import numpy as np\n",
    "import functools\n",
    "import sys \n",
    "ρcrit0 = 2.77533742639e+11 #h^2 Msol / Mpc^3\n",
    "cosmo_params = pickle.load(open('data/cosmo_params.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23af9bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(param_values):\n",
    "    lp = log_prior(param_values)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + log_prob(param_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17f9eaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names = [ 'd1','e0' ,'e1','f0', 'g0','g1']\n",
    "\n",
    "FIXED = {\n",
    "         'f1':0.12,\n",
    "         'd0':2.4,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "210a4e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Box12_1400\n",
      "Skipping Box15_1400\n",
      "Skipping Box21_1400\n",
      "Skipping Box22_1400\n",
      "Skipping Box35_1400\n",
      "Skipping Box36_1400\n",
      "Skipping Box47_1400\n",
      "Skipping Box49_1400\n",
      "Skipping Box52_1400\n",
      "Skipping Box54_1400\n",
      "Skipping Box63_1400\n",
      "Skipping Box70_1400\n",
      "Skipping Box82_1400\n",
      "Skipping Box85_1400\n",
      "Skipping Box95_1400\n"
     ]
    }
   ],
   "source": [
    "from os.path import exists\n",
    "params = {}\n",
    "\n",
    "\n",
    "ndim = len(param_names)\n",
    "for box in cosmo_params:\n",
    "    if('Box5_1400' in box): #something weird going on\n",
    "        continue\n",
    "    #check if there is a fit for this box by checking if the corresponding figure exsits\n",
    "    fig_fname = '/oak/stanford/orgs/kipac/users/delon/aemulusnu_massfunction/figures/%s_fit_%.2f.pdf'%(box, 1.0)\n",
    "    if(not exists(fig_fname)):\n",
    "        print('Skipping %s'%(box))\n",
    "        continue\n",
    "    sampler = None\n",
    "    with open(\"/oak/stanford/orgs/kipac/users/delon/aemulusnu_massfunction/%s_MCMC_sampler.pkl\"%(box), \"rb\") as f:\n",
    "        sampler = pickle.load(f)\n",
    "    samples = sampler.chain[:, 4000:, :].reshape((-1, ndim))\n",
    "    final_param_vals = np.percentile(samples,  50,axis=0)\n",
    "    params[box] = dict(zip(param_names, final_param_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "527d56c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(length, split=0.7):\n",
    "    indices = np.random.permutation(length)\n",
    "    split_len = int(length*split)\n",
    "    return indices[:split_len], indices[split_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "532aa2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f45af4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = [], []\n",
    "for box in params:\n",
    "    X += [list(cosmo_params[box].values())]\n",
    "    Y += [list(params[box].values())]\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "training_idx, testing_idx = train_test_split(len(X), split=0.9)\n",
    "X_train, X_test = X[training_idx], X[testing_idx]\n",
    "Y_train, Y_test = Y[training_idx], Y[testing_idx]\n",
    "\n",
    "box_train = np.array(list(params.keys()))[training_idx]\n",
    "box_test = np.array(list(params.keys()))[testing_idx]\n",
    "\n",
    "\n",
    "X_train, X_test = torch.from_numpy(X_train).float(), torch.from_numpy(X_test).float()\n",
    "Y_train, Y_test = torch.from_numpy(Y_train).float(), torch.from_numpy(Y_test).float()\n",
    "\n",
    "n_tasks = len(Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af3e9bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultitaskGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(MultitaskGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.MultitaskMean(\n",
    "            gpytorch.means.ConstantMean(), num_tasks=n_tasks\n",
    "        )\n",
    "        self.covar_module = gpytorch.kernels.MultitaskKernel(\n",
    "            gpytorch.kernels.RBFKernel(ard_num_dims=X_train.shape[1]), num_tasks=n_tasks, rank=1\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=n_tasks)\n",
    "model = MultitaskGPModel(X_train, Y_train, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27bb3e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ccf7c09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/800 - Loss: 1.344\n",
      "Iter 2/800 - Loss: 1.284\n",
      "Iter 3/800 - Loss: 1.227\n",
      "Iter 4/800 - Loss: 1.171\n",
      "Iter 5/800 - Loss: 1.119\n",
      "Iter 6/800 - Loss: 1.068\n",
      "Iter 7/800 - Loss: 1.020\n",
      "Iter 8/800 - Loss: 0.972\n",
      "Iter 9/800 - Loss: 0.925\n",
      "Iter 10/800 - Loss: 0.876\n",
      "Iter 11/800 - Loss: 0.828\n",
      "Iter 12/800 - Loss: 0.779\n",
      "Iter 13/800 - Loss: 0.732\n",
      "Iter 14/800 - Loss: 0.685\n",
      "Iter 15/800 - Loss: 0.638\n",
      "Iter 16/800 - Loss: 0.593\n",
      "Iter 17/800 - Loss: 0.548\n",
      "Iter 18/800 - Loss: 0.503\n",
      "Iter 19/800 - Loss: 0.459\n",
      "Iter 20/800 - Loss: 0.414\n",
      "Iter 21/800 - Loss: 0.368\n",
      "Iter 22/800 - Loss: 0.322\n",
      "Iter 23/800 - Loss: 0.275\n",
      "Iter 24/800 - Loss: 0.229\n",
      "Iter 25/800 - Loss: 0.185\n",
      "Iter 26/800 - Loss: 0.141\n",
      "Iter 27/800 - Loss: 0.099\n",
      "Iter 28/800 - Loss: 0.057\n",
      "Iter 29/800 - Loss: 0.016\n",
      "Iter 30/800 - Loss: -0.023\n",
      "Iter 31/800 - Loss: -0.061\n",
      "Iter 32/800 - Loss: -0.098\n",
      "Iter 33/800 - Loss: -0.136\n",
      "Iter 34/800 - Loss: -0.172\n",
      "Iter 35/800 - Loss: -0.207\n",
      "Iter 36/800 - Loss: -0.242\n",
      "Iter 37/800 - Loss: -0.277\n",
      "Iter 38/800 - Loss: -0.311\n",
      "Iter 39/800 - Loss: -0.344\n",
      "Iter 40/800 - Loss: -0.377\n",
      "Iter 41/800 - Loss: -0.410\n",
      "Iter 42/800 - Loss: -0.441\n",
      "Iter 43/800 - Loss: -0.471\n",
      "Iter 44/800 - Loss: -0.500\n",
      "Iter 45/800 - Loss: -0.526\n",
      "Iter 46/800 - Loss: -0.552\n",
      "Iter 47/800 - Loss: -0.576\n",
      "Iter 48/800 - Loss: -0.598\n",
      "Iter 49/800 - Loss: -0.617\n",
      "Iter 50/800 - Loss: -0.635\n",
      "Iter 51/800 - Loss: -0.652\n",
      "Iter 52/800 - Loss: -0.668\n",
      "Iter 53/800 - Loss: -0.682\n",
      "Iter 54/800 - Loss: -0.696\n",
      "Iter 55/800 - Loss: -0.710\n",
      "Iter 56/800 - Loss: -0.723\n",
      "Iter 57/800 - Loss: -0.736\n",
      "Iter 58/800 - Loss: -0.749\n",
      "Iter 59/800 - Loss: -0.761\n",
      "Iter 60/800 - Loss: -0.774\n",
      "Iter 61/800 - Loss: -0.785\n",
      "Iter 62/800 - Loss: -0.796\n",
      "Iter 63/800 - Loss: -0.807\n",
      "Iter 64/800 - Loss: -0.817\n",
      "Iter 65/800 - Loss: -0.827\n",
      "Iter 66/800 - Loss: -0.836\n",
      "Iter 67/800 - Loss: -0.846\n",
      "Iter 68/800 - Loss: -0.855\n",
      "Iter 69/800 - Loss: -0.863\n",
      "Iter 70/800 - Loss: -0.871\n",
      "Iter 71/800 - Loss: -0.878\n",
      "Iter 72/800 - Loss: -0.884\n",
      "Iter 73/800 - Loss: -0.889\n",
      "Iter 74/800 - Loss: -0.893\n",
      "Iter 75/800 - Loss: -0.900\n",
      "Iter 76/800 - Loss: -0.908\n",
      "Iter 77/800 - Loss: -0.913\n",
      "Iter 78/800 - Loss: -0.915\n",
      "Iter 79/800 - Loss: -0.919\n",
      "Iter 80/800 - Loss: -0.921\n",
      "Iter 81/800 - Loss: -0.927\n",
      "Iter 82/800 - Loss: -0.933\n",
      "Iter 83/800 - Loss: -0.932\n",
      "Iter 84/800 - Loss: -0.942\n",
      "Iter 85/800 - Loss: -0.943\n",
      "Iter 86/800 - Loss: -0.949\n",
      "Iter 87/800 - Loss: -0.952\n",
      "Iter 88/800 - Loss: -0.957\n",
      "Iter 89/800 - Loss: -0.962\n",
      "Iter 90/800 - Loss: -0.965\n",
      "Iter 91/800 - Loss: -0.968\n",
      "Iter 92/800 - Loss: -0.950\n",
      "Iter 93/800 - Loss: -0.953\n",
      "Iter 94/800 - Loss: -0.969\n",
      "Iter 95/800 - Loss: -0.970\n",
      "Iter 96/800 - Loss: -0.987\n",
      "Iter 97/800 - Loss: -0.985\n",
      "Iter 98/800 - Loss: -0.995\n",
      "Iter 99/800 - Loss: -0.987\n",
      "Iter 100/800 - Loss: -0.943\n",
      "Iter 101/800 - Loss: -0.970\n",
      "Iter 102/800 - Loss: -0.973\n",
      "Iter 103/800 - Loss: -0.988\n",
      "Iter 104/800 - Loss: -0.987\n",
      "Iter 105/800 - Loss: -0.991\n",
      "Iter 106/800 - Loss: -1.003\n",
      "Iter 107/800 - Loss: -1.003\n",
      "Iter 108/800 - Loss: -1.001\n",
      "Iter 109/800 - Loss: -1.008\n",
      "Iter 110/800 - Loss: -1.018\n",
      "Iter 111/800 - Loss: -1.017\n",
      "Iter 112/800 - Loss: -1.014\n",
      "Iter 113/800 - Loss: -0.996\n",
      "Iter 114/800 - Loss: -0.943\n",
      "Iter 115/800 - Loss: -1.022\n",
      "Iter 116/800 - Loss: -1.031\n",
      "Iter 117/800 - Loss: -1.027\n",
      "Iter 118/800 - Loss: -1.057\n",
      "Iter 119/800 - Loss: -1.049\n",
      "Iter 120/800 - Loss: -1.081\n",
      "Iter 121/800 - Loss: -1.071\n",
      "Iter 122/800 - Loss: -1.100\n",
      "Iter 123/800 - Loss: -1.084\n",
      "Iter 124/800 - Loss: -1.113\n",
      "Iter 125/800 - Loss: -1.097\n",
      "Iter 126/800 - Loss: -1.094\n",
      "Iter 127/800 - Loss: -1.112\n",
      "Iter 128/800 - Loss: -1.114\n",
      "Iter 129/800 - Loss: -1.120\n",
      "Iter 130/800 - Loss: -1.126\n",
      "Iter 131/800 - Loss: -1.126\n",
      "Iter 132/800 - Loss: -1.142\n",
      "Iter 133/800 - Loss: -1.133\n",
      "Iter 134/800 - Loss: -1.144\n",
      "Iter 135/800 - Loss: -1.139\n",
      "Iter 136/800 - Loss: -1.148\n",
      "Iter 137/800 - Loss: -1.149\n",
      "Iter 138/800 - Loss: -1.150\n",
      "Iter 139/800 - Loss: -1.150\n",
      "Iter 140/800 - Loss: -1.155\n",
      "Iter 141/800 - Loss: -1.162\n",
      "Iter 142/800 - Loss: -1.165\n",
      "Iter 143/800 - Loss: -1.169\n",
      "Iter 144/800 - Loss: -1.166\n",
      "Iter 145/800 - Loss: -1.170\n",
      "Iter 146/800 - Loss: -1.167\n",
      "Iter 147/800 - Loss: -1.160\n",
      "Iter 148/800 - Loss: -1.146\n",
      "Iter 149/800 - Loss: -1.136\n",
      "Iter 150/800 - Loss: -1.154\n",
      "Iter 151/800 - Loss: -1.177\n",
      "Iter 152/800 - Loss: -1.176\n",
      "Iter 153/800 - Loss: -1.167\n",
      "Iter 154/800 - Loss: -1.173\n",
      "Iter 155/800 - Loss: -1.160\n",
      "Iter 156/800 - Loss: -1.157\n",
      "Iter 157/800 - Loss: -1.181\n",
      "Iter 158/800 - Loss: -1.182\n",
      "Iter 159/800 - Loss: -1.175\n",
      "Iter 160/800 - Loss: -1.190\n",
      "Iter 161/800 - Loss: -1.181\n",
      "Iter 162/800 - Loss: -1.188\n",
      "Iter 163/800 - Loss: -1.191\n",
      "Iter 164/800 - Loss: -1.184\n",
      "Iter 165/800 - Loss: -1.194\n",
      "Iter 166/800 - Loss: -1.192\n",
      "Iter 167/800 - Loss: -1.191\n",
      "Iter 168/800 - Loss: -1.197\n",
      "Iter 169/800 - Loss: -1.193\n",
      "Iter 170/800 - Loss: -1.190\n",
      "Iter 171/800 - Loss: -1.189\n",
      "Iter 172/800 - Loss: -1.154\n",
      "Iter 173/800 - Loss: -1.046\n",
      "Iter 174/800 - Loss: -1.042\n",
      "Iter 175/800 - Loss: -1.169\n",
      "Iter 176/800 - Loss: -1.146\n",
      "Iter 177/800 - Loss: -1.156\n",
      "Iter 178/800 - Loss: -1.154\n",
      "Iter 179/800 - Loss: -1.173\n",
      "Iter 180/800 - Loss: -1.171\n",
      "Iter 181/800 - Loss: -1.171\n",
      "Iter 182/800 - Loss: -1.167\n",
      "Iter 183/800 - Loss: -1.179\n",
      "Iter 184/800 - Loss: -1.177\n",
      "Iter 185/800 - Loss: -1.169\n",
      "Iter 186/800 - Loss: -1.180\n",
      "Iter 187/800 - Loss: -1.180\n",
      "Iter 188/800 - Loss: -1.180\n",
      "Iter 189/800 - Loss: -1.176\n",
      "Iter 190/800 - Loss: -1.184\n",
      "Iter 191/800 - Loss: -1.185\n",
      "Iter 192/800 - Loss: -1.184\n",
      "Iter 193/800 - Loss: -1.185\n",
      "Iter 194/800 - Loss: -1.190\n",
      "Iter 195/800 - Loss: -1.189\n",
      "Iter 196/800 - Loss: -1.189\n",
      "Iter 197/800 - Loss: -1.194\n",
      "Iter 198/800 - Loss: -1.195\n",
      "Iter 199/800 - Loss: -1.194\n",
      "Iter 200/800 - Loss: -1.198\n",
      "Iter 201/800 - Loss: -1.198\n",
      "Iter 202/800 - Loss: -1.199\n",
      "Iter 203/800 - Loss: -1.202\n",
      "Iter 204/800 - Loss: -1.200\n",
      "Iter 205/800 - Loss: -1.203\n",
      "Iter 206/800 - Loss: -1.204\n",
      "Iter 207/800 - Loss: -1.203\n",
      "Iter 208/800 - Loss: -1.207\n",
      "Iter 209/800 - Loss: -1.207\n",
      "Iter 210/800 - Loss: -1.208\n",
      "Iter 211/800 - Loss: -1.208\n",
      "Iter 212/800 - Loss: -1.210\n",
      "Iter 213/800 - Loss: -1.211\n",
      "Iter 214/800 - Loss: -1.209\n",
      "Iter 215/800 - Loss: -1.212\n",
      "Iter 216/800 - Loss: -1.212\n",
      "Iter 217/800 - Loss: -1.211\n",
      "Iter 218/800 - Loss: -1.212\n",
      "Iter 219/800 - Loss: -1.214\n",
      "Iter 220/800 - Loss: -1.214\n",
      "Iter 221/800 - Loss: -1.213\n",
      "Iter 222/800 - Loss: -1.211\n",
      "Iter 223/800 - Loss: -1.208\n",
      "Iter 224/800 - Loss: -1.195\n",
      "Iter 225/800 - Loss: -1.160\n",
      "Iter 226/800 - Loss: -1.081\n",
      "Iter 227/800 - Loss: -1.132\n",
      "Iter 228/800 - Loss: -1.187\n",
      "Iter 229/800 - Loss: -1.189\n",
      "Iter 230/800 - Loss: -1.176\n",
      "Iter 231/800 - Loss: -1.197\n",
      "Iter 232/800 - Loss: -1.186\n",
      "Iter 233/800 - Loss: -1.192\n",
      "Iter 234/800 - Loss: -1.196\n",
      "Iter 235/800 - Loss: -1.188\n",
      "Iter 236/800 - Loss: -1.200\n",
      "Iter 237/800 - Loss: -1.192\n",
      "Iter 238/800 - Loss: -1.197\n",
      "Iter 239/800 - Loss: -1.197\n",
      "Iter 240/800 - Loss: -1.199\n",
      "Iter 241/800 - Loss: -1.197\n",
      "Iter 242/800 - Loss: -1.199\n",
      "Iter 243/800 - Loss: -1.202\n",
      "Iter 244/800 - Loss: -1.200\n",
      "Iter 245/800 - Loss: -1.203\n",
      "Iter 246/800 - Loss: -1.203\n",
      "Iter 247/800 - Loss: -1.205\n",
      "Iter 248/800 - Loss: -1.205\n",
      "Iter 249/800 - Loss: -1.208\n",
      "Iter 250/800 - Loss: -1.207\n",
      "Iter 251/800 - Loss: -1.210\n",
      "Iter 252/800 - Loss: -1.210\n",
      "Iter 253/800 - Loss: -1.210\n",
      "Iter 254/800 - Loss: -1.213\n",
      "Iter 255/800 - Loss: -1.212\n",
      "Iter 256/800 - Loss: -1.214\n",
      "Iter 257/800 - Loss: -1.215\n",
      "Iter 258/800 - Loss: -1.215\n",
      "Iter 259/800 - Loss: -1.216\n",
      "Iter 260/800 - Loss: -1.218\n",
      "Iter 261/800 - Loss: -1.216\n",
      "Iter 262/800 - Loss: -1.218\n",
      "Iter 263/800 - Loss: -1.218\n",
      "Iter 264/800 - Loss: -1.218\n",
      "Iter 265/800 - Loss: -1.218\n",
      "Iter 266/800 - Loss: -1.218\n",
      "Iter 267/800 - Loss: -1.219\n",
      "Iter 268/800 - Loss: -1.220\n",
      "Iter 269/800 - Loss: -1.220\n",
      "Iter 270/800 - Loss: -1.219\n",
      "Iter 271/800 - Loss: -1.218\n",
      "Iter 272/800 - Loss: -1.217\n",
      "Iter 273/800 - Loss: -1.216\n",
      "Iter 274/800 - Loss: -1.212\n",
      "Iter 275/800 - Loss: -1.198\n",
      "Iter 276/800 - Loss: -1.180\n",
      "Iter 277/800 - Loss: -1.159\n",
      "Iter 278/800 - Loss: -1.199\n",
      "Iter 279/800 - Loss: -1.214\n",
      "Iter 280/800 - Loss: -1.203\n",
      "Iter 281/800 - Loss: -1.208\n",
      "Iter 282/800 - Loss: -1.211\n",
      "Iter 283/800 - Loss: -1.209\n",
      "Iter 284/800 - Loss: -1.209\n",
      "Iter 285/800 - Loss: -1.213\n",
      "Iter 286/800 - Loss: -1.209\n",
      "Iter 287/800 - Loss: -1.212\n",
      "Iter 288/800 - Loss: -1.212\n",
      "Iter 289/800 - Loss: -1.212\n",
      "Iter 290/800 - Loss: -1.214\n",
      "Iter 291/800 - Loss: -1.214\n",
      "Iter 292/800 - Loss: -1.214\n",
      "Iter 293/800 - Loss: -1.215\n",
      "Iter 294/800 - Loss: -1.215\n",
      "Iter 295/800 - Loss: -1.217\n",
      "Iter 296/800 - Loss: -1.216\n",
      "Iter 297/800 - Loss: -1.218\n",
      "Iter 298/800 - Loss: -1.217\n",
      "Iter 299/800 - Loss: -1.219\n",
      "Iter 300/800 - Loss: -1.218\n",
      "Iter 301/800 - Loss: -1.220\n",
      "Iter 302/800 - Loss: -1.220\n",
      "Iter 303/800 - Loss: -1.220\n",
      "Iter 304/800 - Loss: -1.221\n",
      "Iter 305/800 - Loss: -1.221\n",
      "Iter 306/800 - Loss: -1.220\n",
      "Iter 307/800 - Loss: -1.221\n",
      "Iter 308/800 - Loss: -1.222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 309/800 - Loss: -1.222\n",
      "Iter 310/800 - Loss: -1.222\n",
      "Iter 311/800 - Loss: -1.222\n",
      "Iter 312/800 - Loss: -1.222\n",
      "Iter 313/800 - Loss: -1.223\n",
      "Iter 314/800 - Loss: -1.223\n",
      "Iter 315/800 - Loss: -1.223\n",
      "Iter 316/800 - Loss: -1.222\n",
      "Iter 317/800 - Loss: -1.222\n",
      "Iter 318/800 - Loss: -1.222\n",
      "Iter 319/800 - Loss: -1.221\n",
      "Iter 320/800 - Loss: -1.220\n",
      "Iter 321/800 - Loss: -1.218\n",
      "Iter 322/800 - Loss: -1.213\n",
      "Iter 323/800 - Loss: -1.208\n",
      "Iter 324/800 - Loss: -1.204\n",
      "Iter 325/800 - Loss: -1.212\n",
      "Iter 326/800 - Loss: -1.221\n",
      "Iter 327/800 - Loss: -1.222\n",
      "Iter 328/800 - Loss: -1.217\n",
      "Iter 329/800 - Loss: -1.220\n",
      "Iter 330/800 - Loss: -1.222\n",
      "Iter 331/800 - Loss: -1.220\n",
      "Iter 332/800 - Loss: -1.221\n",
      "Iter 333/800 - Loss: -1.222\n",
      "Iter 334/800 - Loss: -1.221\n",
      "Iter 335/800 - Loss: -1.221\n",
      "Iter 336/800 - Loss: -1.222\n",
      "Iter 337/800 - Loss: -1.222\n",
      "Iter 338/800 - Loss: -1.221\n",
      "Iter 339/800 - Loss: -1.223\n",
      "Iter 340/800 - Loss: -1.223\n",
      "Iter 341/800 - Loss: -1.222\n",
      "Iter 342/800 - Loss: -1.223\n",
      "Iter 343/800 - Loss: -1.224\n",
      "Iter 344/800 - Loss: -1.223\n",
      "Iter 345/800 - Loss: -1.224\n",
      "Iter 346/800 - Loss: -1.224\n",
      "Iter 347/800 - Loss: -1.223\n",
      "Iter 348/800 - Loss: -1.224\n",
      "Iter 349/800 - Loss: -1.224\n",
      "Iter 350/800 - Loss: -1.224\n",
      "Iter 351/800 - Loss: -1.224\n",
      "Iter 352/800 - Loss: -1.224\n",
      "Iter 353/800 - Loss: -1.224\n",
      "Iter 354/800 - Loss: -1.224\n",
      "Iter 355/800 - Loss: -1.225\n",
      "Iter 356/800 - Loss: -1.224\n",
      "Iter 357/800 - Loss: -1.224\n",
      "Iter 358/800 - Loss: -1.225\n",
      "Iter 359/800 - Loss: -1.224\n",
      "Iter 360/800 - Loss: -1.224\n",
      "Iter 361/800 - Loss: -1.223\n",
      "Iter 362/800 - Loss: -1.221\n",
      "Iter 363/800 - Loss: -1.216\n",
      "Iter 364/800 - Loss: -1.207\n",
      "Iter 365/800 - Loss: -1.190\n",
      "Iter 366/800 - Loss: -1.195\n",
      "Iter 367/800 - Loss: -1.210\n",
      "Iter 368/800 - Loss: -1.223\n",
      "Iter 369/800 - Loss: -1.212\n",
      "Iter 370/800 - Loss: -1.216\n",
      "Iter 371/800 - Loss: -1.219\n",
      "Iter 372/800 - Loss: -1.217\n",
      "Iter 373/800 - Loss: -1.218\n",
      "Iter 374/800 - Loss: -1.219\n",
      "Iter 375/800 - Loss: -1.219\n",
      "Iter 376/800 - Loss: -1.219\n",
      "Iter 377/800 - Loss: -1.220\n",
      "Iter 378/800 - Loss: -1.219\n",
      "Iter 379/800 - Loss: -1.221\n",
      "Iter 380/800 - Loss: -1.221\n",
      "Iter 381/800 - Loss: -1.220\n",
      "Iter 382/800 - Loss: -1.222\n",
      "Iter 383/800 - Loss: -1.221\n",
      "Iter 384/800 - Loss: -1.223\n",
      "Iter 385/800 - Loss: -1.222\n",
      "Iter 386/800 - Loss: -1.223\n",
      "Iter 387/800 - Loss: -1.223\n",
      "Iter 388/800 - Loss: -1.224\n",
      "Iter 389/800 - Loss: -1.224\n",
      "Iter 390/800 - Loss: -1.224\n",
      "Iter 391/800 - Loss: -1.225\n",
      "Iter 392/800 - Loss: -1.224\n",
      "Iter 393/800 - Loss: -1.224\n",
      "Iter 394/800 - Loss: -1.225\n",
      "Iter 395/800 - Loss: -1.225\n",
      "Iter 396/800 - Loss: -1.225\n",
      "Iter 397/800 - Loss: -1.225\n",
      "Iter 398/800 - Loss: -1.225\n",
      "Iter 399/800 - Loss: -1.225\n",
      "Iter 400/800 - Loss: -1.225\n",
      "Iter 401/800 - Loss: -1.224\n",
      "Iter 402/800 - Loss: -1.222\n",
      "Iter 403/800 - Loss: -1.217\n",
      "Iter 404/800 - Loss: -1.208\n",
      "Iter 405/800 - Loss: -1.184\n",
      "Iter 406/800 - Loss: -1.181\n",
      "Iter 407/800 - Loss: -1.193\n",
      "Iter 408/800 - Loss: -1.223\n",
      "Iter 409/800 - Loss: -1.205\n",
      "Iter 410/800 - Loss: -1.214\n",
      "Iter 411/800 - Loss: -1.213\n",
      "Iter 412/800 - Loss: -1.217\n",
      "Iter 413/800 - Loss: -1.212\n",
      "Iter 414/800 - Loss: -1.218\n",
      "Iter 415/800 - Loss: -1.213\n",
      "Iter 416/800 - Loss: -1.217\n",
      "Iter 417/800 - Loss: -1.216\n",
      "Iter 418/800 - Loss: -1.216\n",
      "Iter 419/800 - Loss: -1.218\n",
      "Iter 420/800 - Loss: -1.217\n",
      "Iter 421/800 - Loss: -1.218\n",
      "Iter 422/800 - Loss: -1.219\n",
      "Iter 423/800 - Loss: -1.218\n",
      "Iter 424/800 - Loss: -1.221\n",
      "Iter 425/800 - Loss: -1.219\n",
      "Iter 426/800 - Loss: -1.222\n",
      "Iter 427/800 - Loss: -1.220\n",
      "Iter 428/800 - Loss: -1.222\n",
      "Iter 429/800 - Loss: -1.222\n",
      "Iter 430/800 - Loss: -1.222\n",
      "Iter 431/800 - Loss: -1.224\n",
      "Iter 432/800 - Loss: -1.223\n",
      "Iter 433/800 - Loss: -1.224\n",
      "Iter 434/800 - Loss: -1.225\n",
      "Iter 435/800 - Loss: -1.224\n",
      "Iter 436/800 - Loss: -1.225\n",
      "Iter 437/800 - Loss: -1.225\n",
      "Iter 438/800 - Loss: -1.225\n",
      "Iter 439/800 - Loss: -1.225\n",
      "Iter 440/800 - Loss: -1.226\n",
      "Iter 441/800 - Loss: -1.226\n",
      "Iter 442/800 - Loss: -1.225\n",
      "Iter 443/800 - Loss: -1.225\n",
      "Iter 444/800 - Loss: -1.226\n",
      "Iter 445/800 - Loss: -1.226\n",
      "Iter 446/800 - Loss: -1.226\n",
      "Iter 447/800 - Loss: -1.226\n",
      "Iter 448/800 - Loss: -1.225\n",
      "Iter 449/800 - Loss: -1.224\n",
      "Iter 450/800 - Loss: -1.221\n",
      "Iter 451/800 - Loss: -1.212\n",
      "Iter 452/800 - Loss: -1.183\n",
      "Iter 453/800 - Loss: -1.163\n",
      "Iter 454/800 - Loss: -1.150\n",
      "Iter 455/800 - Loss: -1.221\n",
      "Iter 456/800 - Loss: -1.185\n",
      "Iter 457/800 - Loss: -1.209\n",
      "Iter 458/800 - Loss: -1.198\n",
      "Iter 459/800 - Loss: -1.212\n",
      "Iter 460/800 - Loss: -1.205\n",
      "Iter 461/800 - Loss: -1.207\n",
      "Iter 462/800 - Loss: -1.208\n",
      "Iter 463/800 - Loss: -1.210\n",
      "Iter 464/800 - Loss: -1.204\n",
      "Iter 465/800 - Loss: -1.211\n",
      "Iter 466/800 - Loss: -1.210\n",
      "Iter 467/800 - Loss: -1.208\n",
      "Iter 468/800 - Loss: -1.212\n",
      "Iter 469/800 - Loss: -1.213\n",
      "Iter 470/800 - Loss: -1.210\n",
      "Iter 471/800 - Loss: -1.214\n",
      "Iter 472/800 - Loss: -1.215\n",
      "Iter 473/800 - Loss: -1.214\n",
      "Iter 474/800 - Loss: -1.215\n",
      "Iter 475/800 - Loss: -1.217\n",
      "Iter 476/800 - Loss: -1.217\n",
      "Iter 477/800 - Loss: -1.217\n",
      "Iter 478/800 - Loss: -1.219\n",
      "Iter 479/800 - Loss: -1.218\n",
      "Iter 480/800 - Loss: -1.219\n",
      "Iter 481/800 - Loss: -1.220\n",
      "Iter 482/800 - Loss: -1.220\n",
      "Iter 483/800 - Loss: -1.221\n",
      "Iter 484/800 - Loss: -1.221\n",
      "Iter 485/800 - Loss: -1.222\n",
      "Iter 486/800 - Loss: -1.222\n",
      "Iter 487/800 - Loss: -1.224\n",
      "Iter 488/800 - Loss: -1.223\n",
      "Iter 489/800 - Loss: -1.224\n",
      "Iter 490/800 - Loss: -1.224\n",
      "Iter 491/800 - Loss: -1.225\n",
      "Iter 492/800 - Loss: -1.225\n",
      "Iter 493/800 - Loss: -1.225\n",
      "Iter 494/800 - Loss: -1.226\n",
      "Iter 495/800 - Loss: -1.226\n",
      "Iter 496/800 - Loss: -1.226\n",
      "Iter 497/800 - Loss: -1.227\n",
      "Iter 498/800 - Loss: -1.227\n",
      "Iter 499/800 - Loss: -1.226\n",
      "Iter 500/800 - Loss: -1.226\n",
      "Iter 501/800 - Loss: -1.227\n",
      "Iter 502/800 - Loss: -1.227\n",
      "Iter 503/800 - Loss: -1.227\n",
      "Iter 504/800 - Loss: -1.227\n",
      "Iter 505/800 - Loss: -1.227\n",
      "Iter 506/800 - Loss: -1.227\n",
      "Iter 507/800 - Loss: -1.226\n",
      "Iter 508/800 - Loss: -1.223\n",
      "Iter 509/800 - Loss: -1.214\n",
      "Iter 510/800 - Loss: -1.193\n",
      "Iter 511/800 - Loss: -1.131\n",
      "Iter 512/800 - Loss: -1.170\n",
      "Iter 513/800 - Loss: -1.218\n",
      "Iter 514/800 - Loss: -1.208\n",
      "Iter 515/800 - Loss: -1.217\n",
      "Iter 516/800 - Loss: -1.211\n",
      "Iter 517/800 - Loss: -1.218\n",
      "Iter 518/800 - Loss: -1.213\n",
      "Iter 519/800 - Loss: -1.216\n",
      "Iter 520/800 - Loss: -1.215\n",
      "Iter 521/800 - Loss: -1.217\n",
      "Iter 522/800 - Loss: -1.213\n",
      "Iter 523/800 - Loss: -1.219\n",
      "Iter 524/800 - Loss: -1.215\n",
      "Iter 525/800 - Loss: -1.218\n",
      "Iter 526/800 - Loss: -1.219\n",
      "Iter 527/800 - Loss: -1.217\n",
      "Iter 528/800 - Loss: -1.220\n",
      "Iter 529/800 - Loss: -1.220\n",
      "Iter 530/800 - Loss: -1.220\n",
      "Iter 531/800 - Loss: -1.221\n",
      "Iter 532/800 - Loss: -1.222\n",
      "Iter 533/800 - Loss: -1.222\n",
      "Iter 534/800 - Loss: -1.223\n",
      "Iter 535/800 - Loss: -1.223\n",
      "Iter 536/800 - Loss: -1.224\n",
      "Iter 537/800 - Loss: -1.224\n",
      "Iter 538/800 - Loss: -1.225\n",
      "Iter 539/800 - Loss: -1.225\n",
      "Iter 540/800 - Loss: -1.225\n",
      "Iter 541/800 - Loss: -1.226\n",
      "Iter 542/800 - Loss: -1.226\n",
      "Iter 543/800 - Loss: -1.227\n",
      "Iter 544/800 - Loss: -1.227\n",
      "Iter 545/800 - Loss: -1.228\n",
      "Iter 546/800 - Loss: -1.228\n",
      "Iter 547/800 - Loss: -1.228\n",
      "Iter 548/800 - Loss: -1.229\n",
      "Iter 549/800 - Loss: -1.229\n",
      "Iter 550/800 - Loss: -1.229\n",
      "Iter 551/800 - Loss: -1.230\n",
      "Iter 552/800 - Loss: -1.230\n",
      "Iter 553/800 - Loss: -1.230\n",
      "Iter 554/800 - Loss: -1.230\n",
      "Iter 555/800 - Loss: -1.230\n",
      "Iter 556/800 - Loss: -1.230\n",
      "Iter 557/800 - Loss: -1.229\n",
      "Iter 558/800 - Loss: -1.228\n",
      "Iter 559/800 - Loss: -1.224\n",
      "Iter 560/800 - Loss: -1.211\n",
      "Iter 561/800 - Loss: -1.163\n",
      "Iter 562/800 - Loss: -1.120\n",
      "Iter 563/800 - Loss: -1.091\n",
      "Iter 564/800 - Loss: -1.216\n",
      "Iter 565/800 - Loss: -1.149\n",
      "Iter 566/800 - Loss: -1.205\n",
      "Iter 567/800 - Loss: -1.198\n",
      "Iter 568/800 - Loss: -1.182\n",
      "Iter 569/800 - Loss: -1.199\n",
      "Iter 570/800 - Loss: -1.201\n",
      "Iter 571/800 - Loss: -1.197\n",
      "Iter 572/800 - Loss: -1.194\n",
      "Iter 573/800 - Loss: -1.194\n",
      "Iter 574/800 - Loss: -1.203\n",
      "Iter 575/800 - Loss: -1.202\n",
      "Iter 576/800 - Loss: -1.197\n",
      "Iter 577/800 - Loss: -1.198\n",
      "Iter 578/800 - Loss: -1.205\n",
      "Iter 579/800 - Loss: -1.204\n",
      "Iter 580/800 - Loss: -1.205\n",
      "Iter 581/800 - Loss: -1.204\n",
      "Iter 582/800 - Loss: -1.205\n",
      "Iter 583/800 - Loss: -1.207\n",
      "Iter 584/800 - Loss: -1.208\n",
      "Iter 585/800 - Loss: -1.209\n",
      "Iter 586/800 - Loss: -1.207\n",
      "Iter 587/800 - Loss: -1.209\n",
      "Iter 588/800 - Loss: -1.211\n",
      "Iter 589/800 - Loss: -1.211\n",
      "Iter 590/800 - Loss: -1.210\n",
      "Iter 591/800 - Loss: -1.211\n",
      "Iter 592/800 - Loss: -1.213\n",
      "Iter 593/800 - Loss: -1.212\n",
      "Iter 594/800 - Loss: -1.213\n",
      "Iter 595/800 - Loss: -1.213\n",
      "Iter 596/800 - Loss: -1.214\n",
      "Iter 597/800 - Loss: -1.215\n",
      "Iter 598/800 - Loss: -1.215\n",
      "Iter 599/800 - Loss: -1.216\n",
      "Iter 600/800 - Loss: -1.217\n",
      "Iter 601/800 - Loss: -1.217\n",
      "Iter 602/800 - Loss: -1.218\n",
      "Iter 603/800 - Loss: -1.219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 604/800 - Loss: -1.220\n",
      "Iter 605/800 - Loss: -1.220\n",
      "Iter 606/800 - Loss: -1.221\n",
      "Iter 607/800 - Loss: -1.221\n",
      "Iter 608/800 - Loss: -1.222\n",
      "Iter 609/800 - Loss: -1.223\n",
      "Iter 610/800 - Loss: -1.223\n",
      "Iter 611/800 - Loss: -1.224\n",
      "Iter 612/800 - Loss: -1.225\n",
      "Iter 613/800 - Loss: -1.225\n",
      "Iter 614/800 - Loss: -1.226\n",
      "Iter 615/800 - Loss: -1.226\n",
      "Iter 616/800 - Loss: -1.227\n",
      "Iter 617/800 - Loss: -1.227\n",
      "Iter 618/800 - Loss: -1.228\n",
      "Iter 619/800 - Loss: -1.229\n",
      "Iter 620/800 - Loss: -1.229\n",
      "Iter 621/800 - Loss: -1.229\n",
      "Iter 622/800 - Loss: -1.230\n",
      "Iter 623/800 - Loss: -1.230\n",
      "Iter 624/800 - Loss: -1.230\n",
      "Iter 625/800 - Loss: -1.231\n",
      "Iter 626/800 - Loss: -1.231\n",
      "Iter 627/800 - Loss: -1.231\n",
      "Iter 628/800 - Loss: -1.231\n",
      "Iter 629/800 - Loss: -1.231\n",
      "Iter 630/800 - Loss: -1.231\n",
      "Iter 631/800 - Loss: -1.231\n",
      "Iter 632/800 - Loss: -1.231\n",
      "Iter 633/800 - Loss: -1.230\n",
      "Iter 634/800 - Loss: -1.226\n",
      "Iter 635/800 - Loss: -1.214\n",
      "Iter 636/800 - Loss: -1.156\n",
      "Iter 637/800 - Loss: -1.077\n",
      "Iter 638/800 - Loss: -0.990\n",
      "Iter 639/800 - Loss: -1.190\n",
      "Iter 640/800 - Loss: -1.137\n",
      "Iter 641/800 - Loss: -1.149\n",
      "Iter 642/800 - Loss: -1.205\n",
      "Iter 643/800 - Loss: -1.173\n",
      "Iter 644/800 - Loss: -1.165\n",
      "Iter 645/800 - Loss: -1.178\n",
      "Iter 646/800 - Loss: -1.183\n",
      "Iter 647/800 - Loss: -1.186\n",
      "Iter 648/800 - Loss: -1.186\n",
      "Iter 649/800 - Loss: -1.185\n",
      "Iter 650/800 - Loss: -1.181\n",
      "Iter 651/800 - Loss: -1.181\n",
      "Iter 652/800 - Loss: -1.187\n",
      "Iter 653/800 - Loss: -1.189\n",
      "Iter 654/800 - Loss: -1.192\n",
      "Iter 655/800 - Loss: -1.191\n",
      "Iter 656/800 - Loss: -1.188\n",
      "Iter 657/800 - Loss: -1.190\n",
      "Iter 658/800 - Loss: -1.194\n",
      "Iter 659/800 - Loss: -1.195\n",
      "Iter 660/800 - Loss: -1.195\n",
      "Iter 661/800 - Loss: -1.196\n",
      "Iter 662/800 - Loss: -1.196\n",
      "Iter 663/800 - Loss: -1.197\n",
      "Iter 664/800 - Loss: -1.197\n",
      "Iter 665/800 - Loss: -1.198\n",
      "Iter 666/800 - Loss: -1.199\n",
      "Iter 667/800 - Loss: -1.200\n",
      "Iter 668/800 - Loss: -1.199\n",
      "Iter 669/800 - Loss: -1.200\n",
      "Iter 670/800 - Loss: -1.200\n",
      "Iter 671/800 - Loss: -1.201\n",
      "Iter 672/800 - Loss: -1.202\n",
      "Iter 673/800 - Loss: -1.202\n",
      "Iter 674/800 - Loss: -1.202\n",
      "Iter 675/800 - Loss: -1.203\n",
      "Iter 676/800 - Loss: -1.203\n",
      "Iter 677/800 - Loss: -1.204\n",
      "Iter 678/800 - Loss: -1.204\n",
      "Iter 679/800 - Loss: -1.205\n",
      "Iter 680/800 - Loss: -1.205\n",
      "Iter 681/800 - Loss: -1.206\n",
      "Iter 682/800 - Loss: -1.207\n",
      "Iter 683/800 - Loss: -1.207\n",
      "Iter 684/800 - Loss: -1.208\n",
      "Iter 685/800 - Loss: -1.208\n",
      "Iter 686/800 - Loss: -1.209\n",
      "Iter 687/800 - Loss: -1.209\n",
      "Iter 688/800 - Loss: -1.210\n",
      "Iter 689/800 - Loss: -1.211\n",
      "Iter 690/800 - Loss: -1.211\n",
      "Iter 691/800 - Loss: -1.212\n",
      "Iter 692/800 - Loss: -1.212\n",
      "Iter 693/800 - Loss: -1.213\n",
      "Iter 694/800 - Loss: -1.214\n",
      "Iter 695/800 - Loss: -1.214\n",
      "Iter 696/800 - Loss: -1.215\n",
      "Iter 697/800 - Loss: -1.215\n",
      "Iter 698/800 - Loss: -1.216\n",
      "Iter 699/800 - Loss: -1.217\n",
      "Iter 700/800 - Loss: -1.217\n",
      "Iter 701/800 - Loss: -1.218\n",
      "Iter 702/800 - Loss: -1.219\n",
      "Iter 703/800 - Loss: -1.219\n",
      "Iter 704/800 - Loss: -1.220\n",
      "Iter 705/800 - Loss: -1.220\n",
      "Iter 706/800 - Loss: -1.221\n",
      "Iter 707/800 - Loss: -1.222\n",
      "Iter 708/800 - Loss: -1.222\n",
      "Iter 709/800 - Loss: -1.223\n",
      "Iter 710/800 - Loss: -1.223\n",
      "Iter 711/800 - Loss: -1.224\n",
      "Iter 712/800 - Loss: -1.224\n",
      "Iter 713/800 - Loss: -1.225\n",
      "Iter 714/800 - Loss: -1.226\n",
      "Iter 715/800 - Loss: -1.226\n",
      "Iter 716/800 - Loss: -1.227\n",
      "Iter 717/800 - Loss: -1.227\n",
      "Iter 718/800 - Loss: -1.228\n",
      "Iter 719/800 - Loss: -1.228\n",
      "Iter 720/800 - Loss: -1.229\n",
      "Iter 721/800 - Loss: -1.229\n",
      "Iter 722/800 - Loss: -1.230\n",
      "Iter 723/800 - Loss: -1.230\n",
      "Iter 724/800 - Loss: -1.231\n",
      "Iter 725/800 - Loss: -1.231\n",
      "Iter 726/800 - Loss: -1.231\n",
      "Iter 727/800 - Loss: -1.231\n",
      "Iter 728/800 - Loss: -1.232\n",
      "Iter 729/800 - Loss: -1.232\n",
      "Iter 730/800 - Loss: -1.232\n",
      "Iter 731/800 - Loss: -1.232\n",
      "Iter 732/800 - Loss: -1.232\n",
      "Iter 733/800 - Loss: -1.232\n",
      "Iter 734/800 - Loss: -1.232\n",
      "Iter 735/800 - Loss: -1.232\n",
      "Iter 736/800 - Loss: -1.231\n",
      "Iter 737/800 - Loss: -1.228\n",
      "Iter 738/800 - Loss: -1.218\n",
      "Iter 739/800 - Loss: -1.212\n",
      "Iter 740/800 - Loss: -1.205\n",
      "Iter 741/800 - Loss: -1.147\n",
      "Iter 742/800 - Loss: -1.037\n",
      "Iter 743/800 - Loss: -1.189\n",
      "Iter 744/800 - Loss: -1.167\n",
      "Iter 745/800 - Loss: -1.200\n",
      "Iter 746/800 - Loss: -1.174\n",
      "Iter 747/800 - Loss: -1.201\n",
      "Iter 748/800 - Loss: -1.203\n",
      "Iter 749/800 - Loss: -1.192\n",
      "Iter 750/800 - Loss: -1.196\n",
      "Iter 751/800 - Loss: -1.201\n",
      "Iter 752/800 - Loss: -1.205\n",
      "Iter 753/800 - Loss: -1.200\n",
      "Iter 754/800 - Loss: -1.196\n",
      "Iter 755/800 - Loss: -1.201\n",
      "Iter 756/800 - Loss: -1.207\n",
      "Iter 757/800 - Loss: -1.204\n",
      "Iter 758/800 - Loss: -1.203\n",
      "Iter 759/800 - Loss: -1.203\n",
      "Iter 760/800 - Loss: -1.206\n",
      "Iter 761/800 - Loss: -1.207\n",
      "Iter 762/800 - Loss: -1.207\n",
      "Iter 763/800 - Loss: -1.206\n",
      "Iter 764/800 - Loss: -1.207\n",
      "Iter 765/800 - Loss: -1.208\n",
      "Iter 766/800 - Loss: -1.210\n",
      "Iter 767/800 - Loss: -1.209\n",
      "Iter 768/800 - Loss: -1.209\n",
      "Iter 769/800 - Loss: -1.210\n",
      "Iter 770/800 - Loss: -1.212\n",
      "Iter 771/800 - Loss: -1.212\n",
      "Iter 772/800 - Loss: -1.212\n",
      "Iter 773/800 - Loss: -1.212\n",
      "Iter 774/800 - Loss: -1.214\n",
      "Iter 775/800 - Loss: -1.214\n",
      "Iter 776/800 - Loss: -1.214\n",
      "Iter 777/800 - Loss: -1.215\n",
      "Iter 778/800 - Loss: -1.216\n",
      "Iter 779/800 - Loss: -1.216\n",
      "Iter 780/800 - Loss: -1.217\n",
      "Iter 781/800 - Loss: -1.217\n",
      "Iter 782/800 - Loss: -1.218\n",
      "Iter 783/800 - Loss: -1.219\n",
      "Iter 784/800 - Loss: -1.219\n",
      "Iter 785/800 - Loss: -1.220\n",
      "Iter 786/800 - Loss: -1.220\n",
      "Iter 787/800 - Loss: -1.221\n",
      "Iter 788/800 - Loss: -1.221\n",
      "Iter 789/800 - Loss: -1.222\n",
      "Iter 790/800 - Loss: -1.223\n",
      "Iter 791/800 - Loss: -1.223\n",
      "Iter 792/800 - Loss: -1.224\n",
      "Iter 793/800 - Loss: -1.224\n",
      "Iter 794/800 - Loss: -1.225\n",
      "Iter 795/800 - Loss: -1.226\n",
      "Iter 796/800 - Loss: -1.226\n",
      "Iter 797/800 - Loss: -1.227\n",
      "Iter 798/800 - Loss: -1.227\n",
      "Iter 799/800 - Loss: -1.228\n",
      "Iter 800/800 - Loss: -1.228\n"
     ]
    }
   ],
   "source": [
    "training_iterations = 800\n",
    "for i in range(training_iterations):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X_train)\n",
    "    loss = -mll(output, Y_train)\n",
    "    loss.backward()\n",
    "    print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iterations, loss.item()))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d05015e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from massfunction import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "43f38978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "box =random.choice(box_test)\n",
    "# box = random.choice(box_train)\n",
    "mass_function = MassFunction(cosmo_params[box])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bea131fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/oak/stanford/orgs/kipac/users/delon/miniconda3/envs/massfunction/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:283: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Set into eval mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    predictions = likelihood(model(X_test))\n",
    "    samples = predictions.sample(torch.Size([1000])) \n",
    "    mean = predictions.mean\n",
    "\n",
    "mean = dict(zip(box_test, mean))\n",
    "samples = dict(zip(box_test, np.transpose(samples, axes=[1,0,2])))\n",
    "\n",
    "\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    predictions = likelihood(model(X_train))\n",
    "    samples_train = predictions.sample(torch.Size([1000])) \n",
    "    mean_train = predictions.mean\n",
    "mean_train = dict(zip(box_train, mean_train))\n",
    "samples_train = dict(zip(box_train, np.transpose(samples_train, axes=[1,0,2])))\n",
    "\n",
    "mean = mean | mean_train\n",
    "samples = samples | samples_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a24da0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]/home/users/delon/aemulusnu_massfunction/utils.py:36: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "  res, err = quad(dσ2dk, 0, np.inf)\n",
      "/home/users/delon/aemulusnu_massfunction/utils.py:60: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "  res, err = quad(dσ2dRdk, 0, np.inf)\n",
      "100%|██████████| 16/16 [00:05<00:00,  3.18it/s]\n"
     ]
    }
   ],
   "source": [
    "NvM_fname = '/oak/stanford/orgs/kipac/users/delon/aemulusnu_massfunction/'+box+'_NvsM.pkl'\n",
    "NvM_f = open(NvM_fname, 'rb')\n",
    "NvMs = pickle.load(NvM_f) #NvMs is a dictionary of dictionaries\n",
    "NvM_f.close()\n",
    "\n",
    "N_data = {}\n",
    "M_data = {}\n",
    "aux_data = {}\n",
    "from scipy.interpolate import interp1d, UnivariateSpline, InterpolatedUnivariateSpline\n",
    "\n",
    "vol = -1 #Mpc^3/h^3\n",
    "Mpart = -1\n",
    "\n",
    "for a in tqdm(NvMs.keys()):\n",
    "    if(a != 1): #TEST\n",
    "        continue\n",
    "        \n",
    "    c_data = NvMs[a]\n",
    "    \n",
    "    Ms = c_data['M'] #units of h^-1 Msolar\n",
    "    N = c_data['N']\n",
    "    edge_pairs = c_data['edge_pairs']\n",
    "    assert(len(Ms) == len(edge_pairs))\n",
    "    assert(len(Ms) == len(N))\n",
    "    \n",
    "\n",
    "    if(vol==-1):\n",
    "        vol = c_data['vol']\n",
    "    assert(vol == c_data['vol'])\n",
    "\n",
    "    if(Mpart==-1):\n",
    "        Mpart = c_data['Mpart']\n",
    "    assert(Mpart == c_data['Mpart'])\n",
    "\n",
    "    N_data[a] = []\n",
    "    M_data[a] = []\n",
    "    aux_data[a] = []\n",
    "    for N_curr, M_curr, edge_pair in zip(N, Ms, edge_pairs):\n",
    "        N_data[a] += [N_curr]\n",
    "        M_data[a] += [M_curr]\n",
    "        aux_data[a] += [{'a':a, 'edge_pair':edge_pair}]\n",
    "    \n",
    "    mass_function.compute_dlnsinvdM(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a5cf56d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_numerics = np.logspace(np.log10(100*Mpart), 17, 50)\n",
    "\n",
    "jackknife_covs_fname = '/oak/stanford/orgs/kipac/users/delon/aemulusnu_massfunction/'+box+'_jackknife_covs.pkl'\n",
    "jackknife_covs_f = open(jackknife_covs_fname, 'rb')\n",
    "jackknife = pickle.load(jackknife_covs_f)\n",
    "jackknife_covs_f.close()\n",
    "\n",
    "jack_covs = {a:jackknife[a][1] for a in N_data}\n",
    "\n",
    "# Compute the weighted covariance matrix incorporating jackknife and poisson\n",
    "weighted_cov = {a: jack_covs[a] for a in jack_covs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8985d377",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_list = list(NvMs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d97b23ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 289.80it/s]\n",
      "/tmp/ipykernel_29890/1922378701.py:106: UserWarning: All values for SymLogScale are below linthresh, making it effectively linear. You likely should lower the value of linthresh. \n",
      "  axs[1].axhline(0, c='black')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def estimate_uncertainty(param_combo):\n",
    "    c_params = dict(zip(param_names, param_combo)) | FIXED\n",
    "    tinker_eval_MCMC = [mass_function.tinker(a, M_c, c_params,)*vol for M_c in M_numerics]\n",
    "    f_dndM_MCMC =  interp1d(M_numerics, tinker_eval_MCMC, kind='linear', \n",
    "                            bounds_error=False, fill_value=0.)\n",
    "    tinker_eval_MCMC = np.array([quad(f_dndM_MCMC, edge[0],  edge[1], epsabs=1e-1)[0] for edge in edge_pairs])\n",
    "    return tinker_eval_MCMC\n",
    "\n",
    "for a in reversed(N_data):\n",
    "    if(a != 1):\n",
    "        continue\n",
    "    fig1 = plt.figure(figsize =(12, 7))\n",
    "\n",
    "    axs=[fig1.add_axes((0.2,0.4,.75,.6)), fig1.add_axes((0.2,0.0,.75,.4))]\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    Pk = mass_function.Pka[a]\n",
    "    c_data = NvMs[a]\n",
    "\n",
    "    Ms = M_data[a]\n",
    "    N = N_data[a]\n",
    "    edge_pairs = c_data['edge_pairs']\n",
    "\n",
    "    edges = [edge[0] for edge in edge_pairs]\n",
    "    edges += [edge_pairs[-1][1]]\n",
    "\n",
    "    #shade in 1% and 10% error region\n",
    "    edges = np.array(edges)\n",
    "\n",
    "    y1 = 0.1*np.ones_like(N)\n",
    "    y1 = np.append(y1, y1[-1])\n",
    "    y1 = np.append(y1[0], y1)\n",
    "\n",
    "    y2 = -0.1*np.ones_like(N)\n",
    "    y2 = np.append(y2, y2[-1])\n",
    "    y2 = np.append(y2[0], y2)\n",
    "\n",
    "    c_Ms = np.append(Ms, edges[-1])\n",
    "    c_Ms = np.append(edges[0], c_Ms)\n",
    "    axs[1].fill_between(c_Ms, y1, y2, alpha=1, color='0.95',label='<10% Error')\n",
    "\n",
    "    y1 = 0.01*np.ones_like(N)\n",
    "    y1 = np.append(y1, y1[-1])\n",
    "    y1 = np.append(y1[0], y1)\n",
    "\n",
    "    y2 = -0.01*np.ones_like(N)\n",
    "    y2 = np.append(y2, y2[-1])\n",
    "    y2 = np.append(y2[0], y2)\n",
    "\n",
    "    axs[1].fill_between(c_Ms, y1, y2, alpha=1, color='0.85',label='<1% Error')\n",
    "\n",
    "\n",
    "    dM = np.array([edges[1]-edges[0] for edges in edge_pairs])\n",
    "\n",
    "    \n",
    "\n",
    "    #get uncertainty in emulator prediction\n",
    "    pool = Pool()\n",
    "    uncertainty_estimate = list(tqdm(pool.imap(estimate_uncertainty, samples[box]), \n",
    "                                     total=len(samples[box])))    \n",
    "    emulator_uncertainty = np.std(uncertainty_estimate, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "    #Emulator \n",
    "    c_params = dict(zip(param_names, mean[box])) | FIXED\n",
    "    tinker_eval_MCMC = [mass_function.tinker(a, M_c, c_params,)*vol for M_c in M_numerics]\n",
    "    f_dndM_MCMC =  interp1d(M_numerics, tinker_eval_MCMC, kind='linear', \n",
    "                            bounds_error=False, fill_value=0.)\n",
    "    tinker_eval_MCMC = np.array([quad(f_dndM_MCMC, edge[0],  edge[1], epsabs=1e-1)[0] for edge in edge_pairs])\n",
    "    axs[0].errorbar(Ms, tinker_eval_MCMC, emulator_uncertainty, fmt='x', c='red')\n",
    "    axs[0].bar(x=edges[:-1], height=tinker_eval_MCMC, width=np.diff(edges), \n",
    "               align='edge', fill=False, ec='red', label='Emulator')\n",
    "    axs[1].errorbar(Ms, (tinker_eval_MCMC-N)/N, emulator_uncertainty/N, fmt='x', color='red')\n",
    "\n",
    "    #ML Fit\n",
    "    params = None\n",
    "    if(box in box_test):\n",
    "        params = Y_test[np.where(box_test==box)][0]\n",
    "    elif(box in box_train):\n",
    "        params = Y_train[np.where(box_train==box)][0]\n",
    "\n",
    "    c_params = dict(zip(param_names, params)) | FIXED\n",
    "    tinker_eval_MCMC = [mass_function.tinker(a, M_c, c_params,)*vol for M_c in M_numerics]\n",
    "    f_dndM_MCMC =  interp1d(M_numerics, tinker_eval_MCMC, kind='linear', \n",
    "                            bounds_error=False, fill_value=0.)\n",
    "    tinker_eval_MCMC = np.array([quad(f_dndM_MCMC, edge[0],  edge[1], epsabs=1e-1)[0] for edge in edge_pairs])\n",
    "    axs[0].scatter(Ms, tinker_eval_MCMC, s=50 , marker='x', c='blue')\n",
    "    axs[0].bar(x=edges[:-1], height=tinker_eval_MCMC, width=np.diff(edges), \n",
    "               align='edge', fill=False, ec='blue', label='ML Fit')\n",
    "    axs[1].scatter(Ms, (tinker_eval_MCMC-N)/N, marker='x', color='blue')\n",
    "\n",
    "    #Data\n",
    "    axs[0].bar(x=edges[:-1], height=N, width=np.diff(edges),\n",
    "           align='edge', fill=False, ec='black', label='Data')\n",
    "\n",
    "    axs[0].set_xscale('log')\n",
    "    axs[0].set_yscale('log')\n",
    "    axs[0].legend(frameon=False)\n",
    "    axs[0].set_ylabel('N')\n",
    "\n",
    "    axs[1].set_xscale('log')\n",
    "    axs[1].set_yscale('symlog', linthresh=1e-2)    \n",
    "    axs[1].legend(frameon=False)\n",
    "    axs[1].axhline(0, c='black')\n",
    "    axs[1].set_ylabel('N')\n",
    "    axs[1].set_xlabel(r'Mass $[h^{-1}M_\\odot]$')\n",
    "    axs[1].set_ylabel(r'$\\frac{N_{\\rm Tinker}-N_{\\rm data}}{N_{\\rm data}} $')\n",
    "    axs[0].set_title('%s, a=%.2f, z=%.2f'%(box, a, scaleToRedshift(a)))\n",
    "    i+=1\n",
    "\n",
    "    axs[0].set_xlim((200*Mpart, np.max(edges)))\n",
    "    axs[1].set_xlim((200*Mpart, np.max(edges)))\n",
    "    axs[1].set_ylim((-1e1, 1e1))\n",
    "    plt.savefig('/oak/stanford/orgs/kipac/users/delon/aemulusnu_massfunction/figures/%s_emufit_%.2f.pdf'%(box, a), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcd448c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce982b12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "massfunction",
   "language": "python",
   "name": "massfunction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
