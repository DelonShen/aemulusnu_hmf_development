{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3b9b6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "box = 'Box_n50_0_1400'\n",
    "FIXED = {'d1':-0.6, \n",
    "         'f1':0.16,\n",
    "         'e0':0.1,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "315af235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a17ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mass_function_plots(yerr_dict, params):\n",
    "        i=0\n",
    "        fig_axs = {}\n",
    "        for a in N_data:\n",
    "\n",
    "            z = a_to_z[a]\n",
    "            fig1 = plt.figure(figsize =(12, 7))\n",
    "\n",
    "            axs=[fig1.add_axes((0.2,0.4,.75,.6)), fig1.add_axes((0.2,0.0,.75,.4))]\n",
    "            plt.subplots_adjust(wspace=0, hspace=0)\n",
    "            Pk = Pkz[z]\n",
    "            c_data = NvMs[a]\n",
    "\n",
    "            Ms = M_data[a]\n",
    "            N = N_data[a]\n",
    "            edge_pairs = c_data['edge_pairs']\n",
    "\n",
    "            edges = [edge[0] for edge in edge_pairs]\n",
    "            edges += [edge_pairs[-1][1]]\n",
    "\n",
    "            yerr = yerr_dict[a]\n",
    "            dM = np.array([edges[1]-edges[0] for edges in edge_pairs])\n",
    "            \n",
    "            \n",
    "            tinker_eval_MCMC = [tinker(a, M_c,**params,)*vol for M_c in M_numerics]\n",
    "#             print(tinker_eval_MCMC)\n",
    "\n",
    "#             f_dndM_MCMC_LOG = interp1d(np.log10(M_numerics), tinker_eval_MCMC, kind='linear', bounds_error=False, fill_value=0.)\n",
    "#             f_dndM_MCMC = lambda x:f_dndM_MCMC_LOG(np.log10(x))\n",
    "            f_dndM_MCMC =  interp1d(M_numerics, tinker_eval_MCMC, kind='linear', bounds_error=False, fill_value=0.)\n",
    "\n",
    "            tinker_eval_MCMC = np.array([quad(f_dndM_MCMC, edge[0],  edge[1])[0] for edge in edge_pairs])\n",
    "            color = plt.colormaps[\"rainbow\"]((i+1)/len(Pkz.keys()))[:-1]\n",
    "\n",
    "\n",
    "\n",
    "            axs[0].errorbar(Ms, N, yerr, fmt='+', c='black')\n",
    "            axs[0].scatter(Ms, tinker_eval_MCMC, s=50 , marker='x', c='blue')\n",
    "\n",
    "            edges = np.array(edges)\n",
    "            axs[0].bar(x=edges[:-1], height=N, width=np.diff(edges),\n",
    "                       align='edge', fill=False, ec='black', label='Data')\n",
    "            axs[0].bar(x=edges[:-1], height=tinker_eval_MCMC, width=np.diff(edges), align='edge', fill=False, ec='blue', label='Tinker')\n",
    "            axs[1].errorbar(Ms, (tinker_eval_MCMC-N), yerr, fmt='x', color='blue')\n",
    "\n",
    "            y1 = 0.1*np.array(N)\n",
    "            y1 = np.append(y1, y1[-1])\n",
    "            y1 = np.append(y1[0], y1)\n",
    "\n",
    "            y2 = -0.1*np.array(N)\n",
    "            y2 = np.append(y2, y2[-1])\n",
    "            y2 = np.append(y2[0], y2)\n",
    "\n",
    "            c_Ms = np.append(Ms, edges[-1])\n",
    "            c_Ms = np.append(edges[0], c_Ms)\n",
    "            axs[1].fill_between(c_Ms, y1, y2, alpha=1, color='0.95',label='<10% Error')\n",
    "\n",
    "            y1 = 0.01*np.array(N)\n",
    "            y1 = np.append(y1, y1[-1])\n",
    "            y1 = np.append(y1[0], y1)\n",
    "\n",
    "            y2 = -0.01*np.array(N)\n",
    "            y2 = np.append(y2, y2[-1])\n",
    "            y2 = np.append(y2[0], y2)\n",
    "\n",
    "            axs[1].fill_between(c_Ms, y1, y2, alpha=1, color='0.85',label='<1% Error')\n",
    "\n",
    "\n",
    "            axs[0].set_xscale('log')\n",
    "            axs[0].set_yscale('log')\n",
    "            axs[0].legend(frameon=False)\n",
    "            axs[0].set_ylabel('N')\n",
    "\n",
    "            axs[1].set_xscale('log')\n",
    "            axs[1].set_yscale('symlog', linthresh=1)    \n",
    "            axs[1].legend(frameon=False)\n",
    "            axs[1].axhline(0, c='black')\n",
    "            axs[1].set_ylabel('N')\n",
    "            axs[1].set_xlabel(r'Mass $[h^{-1}M_\\odot]$')\n",
    "            axs[1].set_ylabel(r'${N_{\\rm Tinker}-N_{\\rm data}} $')\n",
    "            axs[0].set_title('%s, a=%.2f, z=%.2f'%(box, a, a_to_z[a]))\n",
    "            i+=1\n",
    "\n",
    "            axs[0].set_xlim((200*Mpart, np.max(edges)))\n",
    "            axs[1].set_xlim((200*Mpart, np.max(edges)))\n",
    "            fig_axs[a] = [fig1, axs]\n",
    "        return fig_axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8bda3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmos_f = open('data/cosmo_params.pkl', 'rb')\n",
    "cosmo_params = pickle.load(cosmos_f) #cosmo_params is a dict\n",
    "cosmos_f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6dc2a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/delon/aemulusnu_massfunction/utils.py:36: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "  res, err = quad(dσ2dk, 0, np.inf)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm, trange\n",
    "from classy import Class\n",
    "import pickle\n",
    "\n",
    "\n",
    "cosmo = cosmo_params[box]\n",
    "h = cosmo['H0']/100\n",
    "cosmo_dict = {\n",
    "    'h': h,\n",
    "    'Omega_b': cosmo['ombh2'] / h**2,\n",
    "    'Omega_cdm': cosmo['omch2'] / h**2,\n",
    "    'N_ur': 0.00641,\n",
    "    'N_ncdm': 1,\n",
    "    'output': 'mPk mTk',\n",
    "    'z_pk': '0.0,99',\n",
    "    'P_k_max_h/Mpc': 20.,\n",
    "    'm_ncdm': cosmo['nu_mass_ev']/3,\n",
    "    'deg_ncdm': 3,\n",
    "    'T_cmb': 2.7255,\n",
    "    'A_s': cosmo['As'] * 10**-9,\n",
    "    'n_s': cosmo['ns'],\n",
    "    'Omega_Lambda': 0.0,\n",
    "    'w0_fld': cosmo['w0'],\n",
    "    'wa_fld': 0.0,\n",
    "    'cs2_fld': 1.0,\n",
    "    'fluid_equation_of_state': \"CLP\"\n",
    "}\n",
    "pkclass = Class()\n",
    "pkclass.set(cosmo_dict)\n",
    "pkclass.compute()\n",
    "\n",
    "curr_run_fname = '/oak/stanford/orgs/kipac/aemulus/aemulus_nu/%s/'%(box)\n",
    "rockstar_dir = curr_run_fname+'output/rockstar/'\n",
    "\n",
    "f = open(rockstar_dir+'savelist.txt', 'r')\n",
    "savelist = f.read().split()\n",
    "f.close()\n",
    "\n",
    "N_snapshots = len(savelist)\n",
    "a = []\n",
    "for i in range(N_snapshots):\n",
    "    f = open(rockstar_dir+'out_%d.list'%(i), 'r')\n",
    "\n",
    "    for line in f:\n",
    "        if('#a' in line):\n",
    "            a+= [eval(line.split()[2])]\n",
    "            break\n",
    "\n",
    "\n",
    "zs = [scaleToRedshift(a_curr) for a_curr in a]\n",
    "\n",
    "Pka = {}\n",
    "for z,a in  zip(zs, a):\n",
    "    kt = np.logspace(-3, 1, 100) # h/Mpc\n",
    "    pk_m_lin = np.array(\n",
    "        [\n",
    "            pkclass.pk_lin(ki, np.array([z]))*h**3 #units of Mpc^3/h^3\n",
    "            for ki in kt * h # 1 / Mpc\n",
    "        ]\n",
    "    )\n",
    "    from scipy.interpolate import interp1d\n",
    "    #given k in units of h/Mpc gives Pk in units of Mpc^3/h^3 \n",
    "    Pk = interp1d(kt, pk_m_lin, kind='linear', bounds_error=False, fill_value=0.)\n",
    "\n",
    "    Pka[a] = Pk    \n",
    "    class_sigma8 = pkclass.sigma(8, z, h_units=True)\n",
    "    my_sigma8 = np.sqrt(sigma2(Pk, 8)) # 8 h^-1 Mpc\n",
    "    assert(np.abs(class_sigma8-my_sigma8)<0.01*class_sigma8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f233756f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import binned_statistic\n",
    "from tqdm import tqdm, trange\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import emcee\n",
    "import sys\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46afe2b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b5fbfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = cosmo_params[box]['H0']/100\n",
    "\n",
    "NvM_fname = '/oak/stanford/orgs/kipac/users/delon/aemulusnu_massfunction/'+box+'_NvsM.pkl'\n",
    "NvM_f = open(NvM_fname, 'rb')\n",
    "NvMs = pickle.load(NvM_f) #NvMs is a dictionary of dictionaries\n",
    "NvM_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b881e5ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80f416c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 36275.06it/s]\n"
     ]
    }
   ],
   "source": [
    "N_data = {}\n",
    "M_data = {}\n",
    "aux_data = {}\n",
    "from scipy.interpolate import interp1d, UnivariateSpline, InterpolatedUnivariateSpline\n",
    "\n",
    "dlnσinvdMs = {}\n",
    "\n",
    "vol = -1 #Mpc^3/h^3\n",
    "Mpart = -1\n",
    "\n",
    "for a in tqdm(Pka.keys()):\n",
    "#     if(a not in LOOKING_AT):\n",
    "#         continue\n",
    "    Pk = Pka[a]\n",
    "    c_data = NvMs[a]\n",
    "    \n",
    "    Ms = c_data['M'] #units of h^-1 Msolar\n",
    "    N = c_data['N']\n",
    "    edge_pairs = c_data['edge_pairs']\n",
    "    assert(len(Ms) == len(edge_pairs))\n",
    "    assert(len(Ms) == len(N))\n",
    "    \n",
    "\n",
    "    if(vol==-1):\n",
    "        vol = c_data['vol']\n",
    "    assert(vol == c_data['vol'])\n",
    "\n",
    "    if(Mpart==-1):\n",
    "        Mpart = c_data['Mpart']\n",
    "    assert(Mpart == c_data['Mpart'])\n",
    "\n",
    "    N_data[a] = []\n",
    "    M_data[a] = []\n",
    "    aux_data[a] = []\n",
    "    for N_curr, M_curr, edge_pair in zip(N, Ms, edge_pairs):\n",
    "        N_data[a] += [N_curr]\n",
    "        M_data[a] += [M_curr]\n",
    "        aux_data[a] += [{'a':a, 'edge_pair':edge_pair}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1966cab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmo_params[box]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e93eaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from massfunction import *\n",
    "mass_function = MassFunction(Pka, cosmo_params[box], dlnσinvdMs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c68a160",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_list = list(NvMs.keys())\n",
    "\n",
    "from scipy.stats import poisson\n",
    "param_names = [ 'd0', 'd1',\n",
    "               'e0', 'e1',\n",
    "               'f0', 'f1',\n",
    "               'g0','g1']\n",
    "\n",
    "\n",
    "M_numerics = np.logspace(np.log10(100*Mpart), 17, 50)\n",
    "\n",
    "jackknife_covs_fname = '/oak/stanford/orgs/kipac/users/delon/aemulusnu_massfunction/'+box+'_jackknife_covs.pkl'\n",
    "jackknife_covs_f = open(jackknife_covs_fname, 'rb')\n",
    "jackknife = pickle.load(jackknife_covs_f)\n",
    "jackknife_covs_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf72640",
   "metadata": {},
   "outputs": [],
   "source": [
    "jack_covs = {a:jackknife[a][1] for a in N_data}\n",
    "\n",
    "# poisson_err = {a:np.sqrt(N_data[a]) for a in N_data}\n",
    "\n",
    "# Compute the weighted covariance matrix incorporating jackknife and poisson\n",
    "weighted_cov = {a: jack_covs[a] for a in jack_covs}\n",
    "\n",
    "# Inverse of the weighted covariance matrix\n",
    "inv_weighted_cov = {a:np.linalg.inv(weighted_cov[a]) for a in weighted_cov}  \n",
    "\n",
    "scale_cov = {a:np.log(np.linalg.det(weighted_cov[a])) for a in weighted_cov}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b3ef73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prior(param_values):\n",
    "    #uniform prior\n",
    "    for param in param_values:\n",
    "        if(np.abs(param) >= 5):\n",
    "            return -np.inf\n",
    "    for a in N_data:\n",
    "        d = p(a, param_values[0], param_values[1])\n",
    "        e = p(a, param_values[2], param_values[3])\n",
    "        f = p(a, param_values[4], param_values[5])\n",
    "        g = p(a, param_values[6], param_values[7])\n",
    "        ps = [d,e,f,g]\n",
    "        for param in ps:\n",
    "            if(param < 0 or param > 5):\n",
    "                return -np.inf\n",
    "    return 0\n",
    "\n",
    "def log_prob(param_values):   \n",
    "    \"\"\"\n",
    "    Calculates the probability of the given tinker parameters \n",
    "    \n",
    "    Args:\n",
    "        param_values (np.ndarray): Input array of shape (number of params).\n",
    "        \n",
    "    Returns:\n",
    "        float: Resulting log probability\n",
    "    \"\"\"\n",
    "\n",
    "    if(log_prior(param_values) == -np.inf):\n",
    "        return -np.inf\n",
    "    \n",
    "    params = dict(zip(param_names, param_values))\n",
    "    tinker_fs = {}\n",
    "    \n",
    "    for a in N_data:\n",
    "        tinker_eval = [tinker(a, M_c,**params,)*vol for M_c in M_numerics]\n",
    "        f_dndlogM = interp1d(M_numerics, tinker_eval, kind='linear', bounds_error=False, fill_value=0.)\n",
    "        tinker_fs[a] = f_dndlogM\n",
    "        \n",
    "    model_vals = {}\n",
    "    for a in N_data:\n",
    "        if(a_to_z[a] >=2):\n",
    "#             print(1)\n",
    "            continue\n",
    "        model_vals[a] = np.array([quad(tinker_fs[a], edge_pair[0], edge_pair[1], epsabs=1e-1)[0]\n",
    "            for edge_pair in NvMs[a]['edge_pairs']\n",
    "        ])\n",
    "    \n",
    "    \n",
    "    residuals = {a: model_vals[a]-N_data[a] for a in model_vals}\n",
    "    log_probs = [ -0.5 * (np.dot(np.dot(residuals[a].T, inv_weighted_cov[a]), residuals[a]) + scale_cov[a]) \n",
    "                 for a in model_vals]\n",
    "    if not np.isfinite(np.sum(log_probs)): \n",
    "        return -np.inf\n",
    "    return np.sum(log_probs)\n",
    "\n",
    "def log_likelihood(param_values):\n",
    "    lp = log_prior(param_values)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + log_prob(param_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1310dd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "guess = np.random.uniform(size=(len(param_names)))\n",
    "while(not np.isfinite(log_likelihood(guess))):\n",
    "    guess = np.random.uniform(size=(len(param_names)))\n",
    "\n",
    "\n",
    "print('Starting ML Fit')\n",
    "#Start by sampling with a maximum likelihood approach\n",
    "from scipy import optimize as optimize\n",
    "nll = lambda *args: -log_likelihood(*args)\n",
    "result = optimize.minimize(nll, guess, method=\"Nelder-Mead\", options={\n",
    "    'maxiter': len(guess)*10000\n",
    "})\n",
    "result['param_names'] = param_names\n",
    "print(box)\n",
    "print(result)\n",
    "print(result['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0258b0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLE_params = dict(zip(param_names, result['x']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8717962f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLE_params = dict(zip(param_names, [ 1.559e+00, -2.079e+00,  1.077e+00,  4.308e+00,  1.358e+00,\n",
    "#                   1.637e-01,  8.069e-01,  4.079e-01]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa72ab9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "yerr_dict = {a:np.sqrt(np.diagonal(weighted_cov[a])) for a in weighted_cov} \n",
    "get_mass_function_plots(yerr_dict, MLE_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f32589",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a79204",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_fname = '/oak/stanford/orgs/kipac/users/delon/aemulusnu_massfunction/'+box+'_MLFit.pkl'\n",
    "result_f = open(result_fname, 'wb')\n",
    "pickle.dump(result, result_f)\n",
    "result_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecea53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwalkers = 64\n",
    "ndim = len(param_names)\n",
    "\n",
    "initialpos = np.array([result['x'] for _ in range(nwalkers)]) + 1e-2 * np.random.normal(size=(nwalkers, ndim))\n",
    "\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "sampler = emcee.EnsembleSampler(\n",
    "    nwalkers = nwalkers,\n",
    "    ndim = ndim,\n",
    "    log_prob_fn = log_likelihood,\n",
    "    pool=Pool()\n",
    ")\n",
    "\n",
    "sampler.run_mcmc(initialpos, 1000, progress=True);\n",
    "\n",
    "with open(\"/oak/stanford/orgs/kipac/users/delon/aemulusnu_massfunction/%s_MCMC_sampler.pkl\"%(box), \"wb\") as f:\n",
    "    pickle.dump(sampler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7da8028",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = param_names\n",
    "\n",
    "import corner\n",
    "samples = sampler.chain[:, 900:, :].reshape((-1, ndim))\n",
    "final_param_vals = np.percentile(samples,  50,axis=0)\n",
    "params_final = dict(zip(param_names, final_param_vals))\n",
    "fig = corner.corner(samples, labels=labels, quantiles=[0.16, 0.5, 0.84],show_titles=True,)\n",
    "\n",
    "plt.savefig('/oak/stanford/orgs/kipac/users/delon/aemulusnu_massfunction/figures/%s_MCMC_corner.pdf'%(box), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74502823",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = param_names\n",
    "\n",
    "fig, axes = plt.subplots(ndim, figsize=(10, 30), sharex=True)\n",
    "samples = sampler.get_chain()\n",
    "print(np.shape(samples))\n",
    "for i in range(ndim):\n",
    "    ax = axes[i]\n",
    "    ax.plot(samples[:, :, i], \"k\", alpha=0.1)\n",
    "    ax.set_xlim(0, len(samples))\n",
    "    ax.set_ylabel(labels[i])\n",
    "    ax.yaxis.set_label_coords(-0.1, 0.5)\n",
    "    ax.axhline(result['x'][i], color='red')\n",
    "    ax.axhline(final_param_vals[i], color='blue')\n",
    "axes[-1].set_xlabel(\"step number\");\n",
    "\n",
    "plt.savefig('/oak/stanford/orgs/kipac/users/delon/aemulusnu_massfunction/figures/%s_MCMC_convergence.pdf'%(box), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e349b45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcd9a16",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "SUFFIX = ''\n",
    "yerr_dict = {a:np.sqrt(np.diagonal(weighted_cov[a])) for a in weighted_cov} \n",
    "fig_axs = get_mass_function_plots(yerr_dict, params_final)\n",
    "for (fig, a) in zip(fig_axs, N_data):\n",
    "    fig_axs[fig][0].savefig('/oak/stanford/orgs/kipac/users/delon/aemulusnu_massfunction/figures/%s_fit_%.2f%s.pdf'%(box, a, SUFFIX), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d21b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "tinker_eval_MCMC = [tinker(a, M_c,**params_final,)*vol for M_c in M_numerics]\n",
    "plt.scatter(M_numerics, tinker_eval_MCMC)\n",
    "f_dndM_MCMC_LOG = interp1d(np.log10(M_numerics), tinker_eval_MCMC, kind='linear', bounds_error=False, fill_value=0.)\n",
    "f_dndM_MCMC = lambda x:f_dndM_MCMC_LOG(np.log10(x))\n",
    "plt.plot(M_numerics, f_dndM_MCMC(M_numerics))\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fff25ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "massfunction",
   "language": "python",
   "name": "massfunction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
