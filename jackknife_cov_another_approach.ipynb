{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c30a60f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import binned_statistic\n",
    "from tqdm import tqdm, trange\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "# box = sys.argv[1]\n",
    "box = 'Box_n50_0_1400'\n",
    "curr_run_fname = '/oak/stanford/orgs/kipac/aemulus/aemulus_nu/%s/'%(box)\n",
    "rockstar_dir = curr_run_fname+'output/rockstar/'\n",
    "\n",
    "f = open(rockstar_dir+'savelist.txt', 'r')\n",
    "savelist = f.read().split()\n",
    "f.close()\n",
    "\n",
    "N_snapshots = len(savelist)\n",
    "\n",
    "i=0\n",
    "\n",
    "import pickle\n",
    "\n",
    "NvMs = {}\n",
    "\n",
    "NvM_fname = '/oak/stanford/orgs/kipac/users/delon/aemulusnu_massfunction/'+curr_run_fname.split('/')[-2]+'_NvsM.pkl'\n",
    "NvM_f = open(NvM_fname, 'rb')\n",
    "NvMs = pickle.load(NvM_f)\n",
    "NvM_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "871cdd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOL = NvMs[0.25]['vol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f96327b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [07:29<00:00, 28.09s/it]\n"
     ]
    }
   ],
   "source": [
    "# jackknife = {}\n",
    "\n",
    "f_pos = open('/oak/stanford/orgs/kipac/users/delon/aemulusnu_massfunction/'+box+'_pos', 'r')\n",
    "\n",
    "tot_bin_idx = []\n",
    "tot_N = []\n",
    "tot_pos = []\n",
    "offsets = {}\n",
    "\n",
    "\n",
    "for a in tqdm(NvMs):\n",
    "    snapshot_pos  = f_pos.readline().strip().split(',')\n",
    "    snapshot_pos  = [np.array(pos.split(), dtype=np.float32) for pos in snapshot_pos if pos != '']\n",
    "    snapshot_pos  = np.array(snapshot_pos)\n",
    "\n",
    "    offsets[a] = len(tot_N)\n",
    "    tot_N += [n for n in NvMs[a]['N']]\n",
    "    tot_bin_idx += [bi+offsets[a]-1 for bi in NvMs[a]['bin_idx'] if bi != 0] #if bi=0 then mass below min mass threshold\n",
    "    tot_pos += [[a, x, y, z] for (i,(x,y,z)) in enumerate(snapshot_pos) if NvMs[a]['bin_idx'][i] != 0]\n",
    "    assert(len(snapshot_pos) == len(NvMs[a]['bin_idx']))\n",
    "    assert(len(tot_pos) == len(tot_bin_idx))\n",
    "f_pos.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e4e173",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(tot_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a9e4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "# Create a k-D tree for spatial subdivision\n",
    "tree = cKDTree(tot_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c15e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters\n",
    "TIME_RANGE = (0.25, 1.0)\n",
    "NUM_SUBREGIONS = 2e8\n",
    "num_particles = np.shape(tot_pos)[0]\n",
    "print(num_particles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe246a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "subregion_size = num_particles // NUM_SUBREGIONS\n",
    "subregion_indices = np.array_split(np.arange(num_particles), NUM_SUBREGIONS)\n",
    "subregions = [tot_pos[idx] for idx in subregion_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74aea8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean histogram\n",
    "mean_histogram = np.mean(histograms, axis=0)\n",
    "\n",
    "# Initialize the covariance matrix\n",
    "covariance = np.zeros((len(a_values) * num_bins, len(a_values) * num_bins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac054b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mass histograms for each spatial region\n",
    "mass_histograms = np.zeros((n_regions, n_time_bins))\n",
    "N_subsamples = 2e10\n",
    "\n",
    "for i in trange(N_subsamples):\n",
    "    curr_N = np.zeros_like(tot_N)\n",
    "    start_idx = i * sample_size\n",
    "    end_idx = start_idx + sample_size\n",
    "    if i == N_subsamples - 1:\n",
    "        end_idx = len(shuffled)  # For the last subsample, adjust end index to include remaining points\n",
    "    for halo in shuffled[start_idx:end_idx]:\n",
    "        curr_N[halo] += 1\n",
    "    #get the number count of halos in the mass bins in this subcube\n",
    "    bin_counts += [curr_N]\n",
    "\n",
    "for i in range(N_subsamples):\n",
    "    region_particles = kdtree.query_ball_point([region_coords[i], region_coords[i], region_coords[i]], region_size)\n",
    "    region_masses = masses[region_particles]\n",
    "    mass_histograms[i] = np.histogram(time_coords[region_particles], bins=time_bins, weights=region_masses)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cc494e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize arrays for mass histograms and mean histogram\n",
    "histograms = np.zeros((tree.n_leaves, len(a_values), num_bins))\n",
    "mean_histogram = np.zeros((len(a_values), num_bins))\n",
    "\n",
    "# Loop over all subspaces\n",
    "for i, leaf in enumerate(tree.query_ball_tree(tree, subspace_size)):\n",
    "\n",
    "    # Get the particles in the current subspace\n",
    "    subspace_particles = space[leaf]\n",
    "\n",
    "    # Calculate the mass in each bin for each `a` value\n",
    "    for j, a_val in enumerate(a_values):\n",
    "        # Get the particles with the current `a` value\n",
    "        a_particles = subspace_particles[subspace_particles[:, 0] == a_val]\n",
    "        # Calculate the bin indices for each particle\n",
    "        bin_indices = np.floor(num_bins * a_particles[:, 1:]).astype(int)\n",
    "        # Sum the mass in each bin\n",
    "        for k in range(num_bins):\n",
    "            histograms[i, j, k] = np.sum(a_particles[bin_indices == k, 0])\n",
    "\n",
    "    # Calculate the mean histogram over all subspaces\n",
    "    mean_histogram += histograms[i] / tree.n_leaves\n",
    "\n",
    "# Initialize array for covariance matrix\n",
    "covariance = np.zeros((len(a_values) * num_bins, len(a_values) * num_bins))\n",
    "\n",
    "# Loop over all subspaces and calculate the mean histogram without that subspace\n",
    "for i, leaf in enumerate(tree.query_ball_tree(tree, subspace_size)):\n",
    "    # Get the mass histograms for all other subspaces\n",
    "    other_histograms = histograms[np.setdiff1d(np.arange(tree.n_leaves), i)]\n",
    "    # Calculate the mean histogram without the current subspace\n",
    "    other_mean_histogram = np.sum(other_histograms, axis=0) / (tree.n_leaves - 1)\n",
    "    # Calculate the contribution of the current subs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1d5868",
   "metadata": {},
   "outputs": [],
   "source": [
    "jackknife_covs_fname = '/oak/stanford/orgs/kipac/users/delon/aemulusnu_massfunction/'+curr_run_fname.split('/')[-2]+'_jackknife_covs.pkl'\n",
    "jackknife_covs_f = open(jackknife_covs_fname, 'wb')\n",
    "pickle.dump(jackknife, jackknife_covs_f)\n",
    "jackknife_covs_f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "massfunction",
   "language": "python",
   "name": "massfunction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
