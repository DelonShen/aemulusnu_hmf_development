{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebc1522c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import binned_statistic\n",
    "from tqdm import tqdm, trange\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "# box = sys.argv[1]\n",
    "# box = 'Box_n50_0_1400'\n",
    "box = 'Box0_1400'\n",
    "curr_run_fname = '/oak/stanford/orgs/kipac/aemulus/aemulus_nu/%s/'%(box)\n",
    "rockstar_dir = curr_run_fname+'output/rockstar/'\n",
    "\n",
    "f = open(rockstar_dir+'savelist.txt', 'r')\n",
    "savelist = f.read().split()\n",
    "f.close()\n",
    "\n",
    "N_snapshots = len(savelist)\n",
    "\n",
    "i=0\n",
    "\n",
    "import pickle\n",
    "\n",
    "NvMs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40e58497",
   "metadata": {},
   "outputs": [],
   "source": [
    "NvM_fname = '/oak/stanford/orgs/kipac/users/delon/aemulusnu_massfunction/'+box+'_NvsM.pkl'\n",
    "NvM_f = open(NvM_fname, 'rb')\n",
    "NvMs = pickle.load(NvM_f)\n",
    "NvM_f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "251e591e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:18<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22274431,) (240,)\n"
     ]
    }
   ],
   "source": [
    "jackknife_NEW = {}\n",
    "\n",
    "tot_bin_idx = []\n",
    "tot_N = []\n",
    "offsets = {}\n",
    "for a in tqdm(NvMs):\n",
    "    offsets[a] = len(tot_N)\n",
    "    tot_N += [n for n in NvMs[a]['N']]\n",
    "    tot_bin_idx += [bi+offsets[a]-1 for bi in NvMs[a]['bin_idx'] if bi != 0] #if bi=0 then mass below min mass threshold\n",
    "tot_bin_idx = np.array(tot_bin_idx)\n",
    "tot_N = np.array(tot_N)\n",
    "print(tot_bin_idx.shape, tot_N.shape)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1310f26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05e72792",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 524288/524288 [00:12<00:00, 42302.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(524288, 240)\n"
     ]
    }
   ],
   "source": [
    "bin_counts = []\n",
    "\n",
    "\n",
    "N_subsamples = int(2**19)\n",
    "\n",
    "#compute the indices of the smaller cube that each point belongs to\n",
    "shuffled = np.copy(tot_bin_idx)\n",
    "np.random.shuffle(shuffled)\n",
    "\n",
    "sample_size = len(shuffled) // N_subsamples  # Number of points in each subsample\n",
    "\n",
    "for i in trange(N_subsamples):\n",
    "    curr_N = np.zeros_like(tot_N)\n",
    "    start_idx = i * sample_size\n",
    "    end_idx = start_idx + sample_size\n",
    "    if i == N_subsamples - 1:\n",
    "        end_idx = len(shuffled)  # For the last subsample, adjust end index to include remaining points\n",
    "    for halo in shuffled[start_idx:end_idx]:\n",
    "        curr_N[halo] += 1\n",
    "    #get the number count of halos in the mass bins when leaving out this subsample\n",
    "    bin_counts += [tot_N-curr_N]\n",
    "\n",
    "# Calculate the mean mass histogram over all random partitions\n",
    "mean_histogram = np.mean(bin_counts, axis=0)\n",
    "\n",
    "# Calculate the deviations from the mean for each mass bin for each random partition\n",
    "deviations = bin_counts - mean_histogram\n",
    "print(np.shape(deviations))\n",
    "# Calculate the covariance matrix using the deviations from the mean for all random partitions\n",
    "covariance = np.cov(deviations.T)\n",
    "\n",
    "correction_factor =  N_subsamples/(N_subsamples - 1) \n",
    "covariance *= correction_factor\n",
    "\n",
    "tmp += [covariance[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f1dc7e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07507481225391988"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covariance[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "910f83dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07507481225391988"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covariance[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c15c43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_covariance_matrix(matrix):\n",
    "    \"\"\"\n",
    "    Checks if a matrix is a valid covariance matrix.\n",
    "    \n",
    "    Args:\n",
    "    matrix: a 2D numpy array representing the matrix\n",
    "    \n",
    "    Returns:\n",
    "    True if the matrix is a valid covariance matrix, False otherwise\n",
    "    \"\"\"\n",
    "    # Check if the matrix is square\n",
    "    if matrix.shape[0] != matrix.shape[1]:\n",
    "        return False\n",
    "    \n",
    "    # Check if the matrix is symmetric\n",
    "    if not np.allclose(matrix, matrix.T):\n",
    "        return False\n",
    "    \n",
    "    # Check if the matrix is positive semidefinite\n",
    "    if not np.all(np.linalg.eigvals(matrix) >= 0):\n",
    "        return False\n",
    "    \n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ff7ee3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af104323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True 0.07507481225391988\n"
     ]
    }
   ],
   "source": [
    "print(is_covariance_matrix(covariance), covariance[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6deb6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "jackknife_covs_fname = '/oak/stanford/orgs/kipac/users/delon/aemulusnu_massfunction/'+curr_run_fname.split('/')[-2]+'_jackknife_covs.pkl'\n",
    "jackknife_covs_f = open(jackknife_covs_fname, 'wb')\n",
    "pickle.dump(covariance, jackknife_covs_f)\n",
    "jackknife_covs_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8202a3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7791e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "jackknife = {}\n",
    "\n",
    "f_pos = open('/oak/stanford/orgs/kipac/users/delon/aemulusnu_massfunction/'+box+'_pos', 'r')\n",
    "\n",
    "\n",
    "for a in NvMs:\n",
    "    snapshot_pos  = f_pos.readline().strip().split(',')\n",
    "    snapshot_pos  = [np.array(pos.split(), dtype=np.float32) for pos in snapshot_pos if pos != '']\n",
    "    snapshot_pos  = np.array(snapshot_pos)\n",
    "\n",
    "    bin_cnters = NvMs[a]['M']\n",
    "    N = NvMs[a]['N']\n",
    "    vol = NvMs[a]['vol']\n",
    "    Mpart = NvMs[a]['Mpart']\n",
    "    edge_pairs = NvMs[a]['edge_pairs']\n",
    "    bin_idx = NvMs[a]['bin_idx']\n",
    "    print(a, np.min(bin_idx), np.max(bin_idx))\n",
    "    print(len(bin_idx), len(N))\n",
    "    #redefine the edges that we'll jackknife on \n",
    "    edges = [edge[0] for edge in edge_pairs]\n",
    "    edges += [edge_pairs[-1][1]]    \n",
    "\n",
    "    #now lets get to spatial jackknife\n",
    "    N_DIVS = 8 #each axis is diided into N_DIVS parts so in total the box\n",
    "               #is divided into N_DIVS**3 boxes\n",
    "\n",
    "    #compute the size of each smaller cube\n",
    "    ϵ = vol*10**(-6)\n",
    "    cube_vol = (vol+ε) / N_DIVS**3 #need ϵ to properly handle halos directly on boundary \n",
    "    cube_size = np.cbrt(cube_vol)\n",
    "\n",
    "    #compute the indices of the smaller cube that each point belongs to\n",
    "    cube_indices = (snapshot_pos / cube_size).astype(int)\n",
    "\n",
    "    #cube_indices has assignment of halo to 3d position of a voxel\n",
    "    #ravel_multi_index indexes the voxels in 3D with a single integer\n",
    "    cube_assignment = np.ravel_multi_index(cube_indices.T, (N_DIVS, N_DIVS, N_DIVS), order='F')\n",
    "    \n",
    "    bin_counts = []\n",
    "    \n",
    "    print(len(cube_assignment), len(bin_idx))\n",
    "    for i in trange(N_DIVS**3):\n",
    "        current_cube = np.where(cube_assignment == i)\n",
    "        curr_N = np.zeros_like(N)\n",
    "        for halo in bin_idx[current_cube]:\n",
    "            #halo=1 corresponds to first bin \n",
    "            if(halo==0): #not in any bin \n",
    "                continue\n",
    "            curr_N[halo-1] += 1\n",
    "        #get the number count of halos in the mass bins in this subcube\n",
    "        bin_counts += [curr_N]\n",
    "    bin_counts = np.array(bin_counts)\n",
    "    mean_counts = np.mean(bin_counts, axis=0)\n",
    "    dev_counts = bin_counts - mean_counts\n",
    "#     print('aaaa')\n",
    "#     print(np.shape(bin_counts))\n",
    "#     print(np.shape(dev_counts))\n",
    "#     print(np.shape(mean_counts))\n",
    "#     print('aaaa')\n",
    "\n",
    "    cov_counts = np.zeros((len(mean_counts), len(mean_counts)))    \n",
    "\n",
    "    for i in range(N_DIVS**3):\n",
    "        # Remove the i-th sub-cube from the sample and calculate the jackknife estimate\n",
    "        leave_out_idx = np.where(np.arange(N_DIVS**3) != i)\n",
    "        jackknife_counts = np.mean(bin_counts[leave_out_idx], axis=0)\n",
    "        dev_jackknife = jackknife_counts - mean_counts\n",
    "#         print(np.shape(dev_jackknife))\n",
    "#         print(np.shape(dev_counts[i]))\n",
    "\n",
    "        cov_counts += np.outer(dev_counts[i], dev_jackknife)\n",
    "\n",
    "    jackknife_covariance = (N_DIVS**3 - 1)/N_DIVS**3 * cov_counts\n",
    "\n",
    "\n",
    "#     print(len(N), jackknife_covariance.shape)\n",
    "    jackknife[a] = [bin_counts, jackknife_covariance]\n",
    "    break\n",
    "f_pos.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a76363",
   "metadata": {},
   "outputs": [],
   "source": [
    "jackknife[a][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a62311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from multiprocessing import Pool, cpu_count\n",
    "# from functools import partial\n",
    "\n",
    "# def process_sample(i):\n",
    "#     leave_out_idx = np.where(np.arange(N_subsamples) != i)\n",
    "#     jackknife_counts = np.mean(bin_counts[leave_out_idx], axis=0)\n",
    "#     dev_jackknife = jackknife_counts - mean_counts\n",
    "# #     print(np.shape(dev_jackknife))\n",
    "# #     print(N_subsamples)\n",
    "#     return np.outer(dev_counts[i], dev_jackknife)\n",
    "\n",
    "# N_subsamples = int(2**15)\n",
    "\n",
    "# #compute the indices of the smaller cube that each point belongs to\n",
    "# shuffled = np.copy(tot_bin_idx)\n",
    "# np.random.shuffle(shuffled)\n",
    "\n",
    "# sample_size = len(shuffled) // N_subsamples  # Number of points in each subsample\n",
    "\n",
    "\n",
    "# bin_counts = []\n",
    "\n",
    "# for i in trange(N_subsamples):\n",
    "#     curr_N = np.zeros_like(tot_N)\n",
    "#     start_idx = i * sample_size\n",
    "#     end_idx = start_idx + sample_size\n",
    "#     if i == N_subsamples - 1:\n",
    "#         end_idx = len(shuffled)  # For the last subsample, adjust end index to include remaining points\n",
    "#     for halo in shuffled[start_idx:end_idx]:\n",
    "#         curr_N[halo] += 1\n",
    "#     #get the number count of halos in the mass bins in this subcube\n",
    "#     bin_counts += [curr_N]\n",
    "\n",
    "\n",
    "# bin_counts = np.array(bin_counts)\n",
    "# mean_counts = np.mean(bin_counts, axis=0)\n",
    "# dev_counts = bin_counts - mean_counts\n",
    "\n",
    "\n",
    "# cov_counts = np.zeros((len(mean_counts), len(mean_counts)))    \n",
    "\n",
    "# assert(N_subsamples == len(bin_counts))\n",
    "\n",
    "\n",
    "# # Set up the multiprocessing pool\n",
    "# pool = Pool()\n",
    "# # Create a new function with some arguments pre-set\n",
    "\n",
    "# # Map the function across the loop\n",
    "# results = list(tqdm(pool.imap(process_sample, range(N_subsamples)), total=N_subsamples))\n",
    "# # Combine the results\n",
    "# cov_counts += sum(results)    \n",
    "\n",
    "# full_cov = (N_subsamples - 1)/N_subsamples * cov_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4632599",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(tmp_full_cov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840434fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = [get_cov(2**i)[0][0] for i in range(13, 16)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df1abcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(list(range(12, 14)), data[-2:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2595e066",
   "metadata": {},
   "outputs": [],
   "source": [
    "jackknife_covs_fname = '/oak/stanford/orgs/kipac/users/delon/aemulusnu_massfunction/'+curr_run_fname.split('/')[-2]+'_jackknife_covs.pkl'\n",
    "jackknife_covs_f = open(jackknife_covs_fname, 'wb')\n",
    "pickle.dump(full_cov, jackknife_covs_f)\n",
    "jackknife_covs_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e0041b",
   "metadata": {},
   "outputs": [],
   "source": [
    "jackknife = {}\n",
    "\n",
    "f_pos = open('/oak/stanford/orgs/kipac/users/delon/aemulusnu_massfunction/'+box+'_pos', 'r')\n",
    "\n",
    "\n",
    "for a in NvMs:\n",
    "    snapshot_pos  = f_pos.readline().strip().split(',')\n",
    "    snapshot_pos  = [np.array(pos.split(), dtype=np.float32) for pos in snapshot_pos if pos != '']\n",
    "    snapshot_pos  = np.array(snapshot_pos)\n",
    "\n",
    "    bin_cnters = NvMs[a]['M']\n",
    "    N = NvMs[a]['N']\n",
    "    vol = NvMs[a]['vol']\n",
    "    Mpart = NvMs[a]['Mpart']\n",
    "    bin_idx = NvMs[a]['bin_idx']\n",
    "    print(a, np.min(bin_idx), np.max(bin_idx))\n",
    "    print(len(bin_idx), len(N))\n",
    "\n",
    "    #now lets get to spatial jackknife\n",
    "    N_DIVS = 8 #each axis is diided into N_DIVS parts so in total the box\n",
    "               #is divided into N_DIVS**3 boxes\n",
    "\n",
    "    #compute the size of each smaller cube\n",
    "    ϵ = vol*10**(-6)\n",
    "    cube_vol = (vol+ε) / N_DIVS**3 #need ϵ to properly handle halos directly on boundary \n",
    "    cube_size = np.cbrt(cube_vol)\n",
    "\n",
    "    #compute the indices of the smaller cube that each point belongs to\n",
    "    cube_indices = (snapshot_pos / cube_size).astype(int)\n",
    "\n",
    "    #cube_indices has assignment of halo to 3d position of a voxel\n",
    "    #ravel_multi_index indexes the voxels in 3D with a single integer\n",
    "    cube_assignment = np.ravel_multi_index(cube_indices.T, (N_DIVS, N_DIVS, N_DIVS), order='F')\n",
    "    \n",
    "    bin_counts = []\n",
    "    \n",
    "    print(len(cube_assignment), len(bin_idx))\n",
    "    for i in trange(N_DIVS**3):\n",
    "        current_cube = np.where(cube_assignment == i)\n",
    "        curr_N = np.zeros_like(N)\n",
    "        for halo in bin_idx[current_cube]:\n",
    "            #halo=1 corresponds to first bin \n",
    "            if(halo==0): #not in any bin \n",
    "                continue\n",
    "            curr_N[halo-1] += 1\n",
    "        #get the number count of halos in the mass bins in this subcube\n",
    "        bin_counts += [curr_N]\n",
    "    bin_counts = np.array(bin_counts)\n",
    "    mean_counts = np.mean(bin_counts, axis=0)\n",
    "    dev_counts = bin_counts - mean_counts\n",
    "#     print('aaaa')\n",
    "#     print(np.shape(bin_counts))\n",
    "#     print(np.shape(dev_counts))\n",
    "#     print(np.shape(mean_counts))\n",
    "#     print('aaaa')\n",
    "\n",
    "    cov_counts = np.zeros((len(mean_counts), len(mean_counts)))    \n",
    "\n",
    "    for i in range(N_DIVS**3):\n",
    "        # Remove the i-th sub-cube from the sample and calculate the jackknife estimate\n",
    "        leave_out_idx = np.where(np.arange(N_DIVS**3) != i)\n",
    "        jackknife_counts = np.mean(bin_counts[leave_out_idx], axis=0)\n",
    "        dev_jackknife = jackknife_counts - mean_counts\n",
    "#         print(np.shape(dev_jackknife))\n",
    "#         print(np.shape(dev_counts[i]))\n",
    "\n",
    "        cov_counts += np.outer(dev_counts[i], dev_jackknife)\n",
    "\n",
    "    jackknife_covariance = (N_DIVS**3 - 1)/N_DIVS**3 * cov_counts\n",
    "\n",
    "\n",
    "#     print(len(N), jackknife_covariance.shape)\n",
    "    jackknife[a] = [bin_counts, jackknife_covariance]\n",
    "f_pos.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8212d842",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fdfc90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "massfunction",
   "language": "python",
   "name": "massfunction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
