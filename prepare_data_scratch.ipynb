{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aecabedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import binned_statistic\n",
    "from tqdm import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16026426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# box = sys.argv[1]\n",
    "# box = 'Box_n50_0_1400'\n",
    "box = 'Box0_1400'\n",
    "curr_run_fname = '/oak/stanford/orgs/kipac/aemulus/aemulus_nu/%s/'%(box)\n",
    "rockstar_dir = curr_run_fname+'output/rockstar/'\n",
    "\n",
    "f = open(rockstar_dir+'savelist.txt', 'r')\n",
    "savelist = f.read().split()\n",
    "f.close()\n",
    "\n",
    "N_snapshots = len(savelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2798f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "print(N_snapshots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae406456",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:33,  2.10s/it]\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "\n",
    "import pickle\n",
    "\n",
    "NvMs = {}\n",
    "f = open('/oak/stanford/orgs/kipac/users/delon/aemulusnu_massfunction/'+box+'_M200b', 'r')\n",
    "\n",
    "TMP=0\n",
    "for line in tqdm(f):\n",
    "#     fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(13,8))\n",
    "\n",
    "    #extract the masses and position of halos for a given snapshot \n",
    "    snapshot_mass = line.strip().split()\n",
    "    snapshot_mass = np.array(snapshot_mass, dtype=np.float64)  \n",
    "    \n",
    "\n",
    "\n",
    "    f = open(rockstar_dir+'out_%d.list'%(i), 'r')\n",
    "    \n",
    "    #get the volume, redshift, and particle mass in the simulation\n",
    "    vol = -1\n",
    "    BOX_SIZE = -1\n",
    "    a = -1\n",
    "    Mpart = -1\n",
    "    for line in f:\n",
    "        if('#a' in line):\n",
    "            a = eval(line.split()[2])\n",
    "        if('Particle mass' in line):\n",
    "            Mpart = eval(line.split()[2])\n",
    "        if('Box size' in line):\n",
    "            vol = eval(line.split()[2])**3\n",
    "            BOX_SIZE = eval(line.split()[2])\n",
    "            break\n",
    "            \n",
    "    \n",
    "    \n",
    "    nBins = 16\n",
    "    \n",
    "    #we'll only consider halos with more than 200 particles\n",
    "    edges_log10 = np.arange(np.log10(200*Mpart), 1+np.log10(np.max(snapshot_mass)), 0.1)\n",
    "    edges = np.array([10**el10 for el10 in edges_log10])\n",
    "\n",
    "    #get the number count of halos in the mass bins\n",
    "    N, bin_edge, bin_idx = binned_statistic(snapshot_mass, np.ones_like(snapshot_mass), \n",
    "                                            statistic='count', bins=edges)\n",
    "    c_i = len(N)-1\n",
    "    while(N[c_i] == 0):\n",
    "        N = N[:c_i]\n",
    "        bin_edge = bin_edge[:(c_i+1)]\n",
    "        c_i -= 1\n",
    "#         print('---')\n",
    "#         print(N)\n",
    "#         print(bin_edge)\n",
    "#         print('---')\n",
    "\n",
    "        \n",
    "    #make large mass bin have at least 20 halos\n",
    "    while(N[c_i] < 20):\n",
    "        N[c_i-1] += N[c_i]\n",
    "        halos_here = np.where(bin_idx==c_i+1)\n",
    "        bin_idx[halos_here] = c_i\n",
    "        N = N[:c_i]\n",
    "        bin_edge = np.delete(bin_edge,c_i)\n",
    "        c_i -= 1\n",
    "#         print('---')\n",
    "#         print(N)\n",
    "#         print(bin_edge)\n",
    "#         print('---')\n",
    "\n",
    "        \n",
    "    M_means = []\n",
    "    correction = np.zeros_like(N)\n",
    "    \n",
    "    for j in range(len(N)):\n",
    "        this_bin = np.where(bin_idx == j+1)\n",
    "        M_means += [np.mean(snapshot_mass[this_bin])]\n",
    "#         print(N[j], len(snapshot_mass[this_bin]))\n",
    "        assert(len(snapshot_mass[this_bin]) == N[j])\n",
    "            \n",
    "    edge_pairs = [[bin_edge[i], bin_edge[i+1]] for i in range(len(bin_edge)-1)]\n",
    "    assert(len(edge_pairs) == len(N))\n",
    "#     ax.bar(x=bin_edge[:-1], height=N, width=np.diff(bin_edge), align='edge', fill=False, label=r'$a=%.2f$'%(a))\n",
    "\n",
    "#     ax.set_title(curr_run_fname.split('/')[-2])\n",
    "#     ax.set_xscale('log')\n",
    "#     ax.set_yscale('log')\n",
    "#     ax.set_xlabel(r'Mass $[h^{-1}M_\\odot]$')\n",
    "#     ax.set_ylabel(r'$N$')\n",
    "#     ax.legend(frameon=False)\n",
    "\n",
    "#     plt.savefig('/oak/stanford/orgs/kipac/users/delon/aemulusnu_massfunction/figures/'+curr_run_fname.split('/')[-2]+'_NvsM_a%.1f.pdf'%(a), bbox_inches='tight')\n",
    "\n",
    "    i+=1\n",
    "    assert(len(edge_pairs) == len(N))\n",
    "    NvMs[a] = {'M':M_means, \n",
    "               'N':N, \n",
    "               'vol':vol, \n",
    "               'Mpart':Mpart, \n",
    "               'edge_pairs':edge_pairs,\n",
    "               'bin_idx':bin_idx,\n",
    "               'corrections':correction}\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52adfe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "NvM_fname = '/oak/stanford/orgs/kipac/users/delon/aemulusnu_massfunction/'+curr_run_fname.split('/')[-2]+'_NvsM.pkl'\n",
    "NvM_f = open(NvM_fname, 'wb')\n",
    "pickle.dump(NvMs, NvM_f)\n",
    "NvM_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0282c3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [04:34<00:00, 17.15s/it]\n"
     ]
    }
   ],
   "source": [
    "jackknife = {}\n",
    "f_pos = open('/oak/stanford/orgs/kipac/users/delon/aemulusnu_massfunction/'+box+'_pos', 'r')\n",
    "for a in tqdm(NvMs):\n",
    "    snapshot_pos  = f_pos.readline().strip().split(',')\n",
    "    snapshot_pos  = [np.array(pos.split(), dtype=np.float32) for pos in snapshot_pos if pos != '']\n",
    "    snapshot_pos  = np.array(snapshot_pos)\n",
    "\n",
    "    N = NvMs[a]['N']\n",
    "    vol = NvMs[a]['vol']\n",
    "    bin_idx = NvMs[a]['bin_idx']\n",
    "    correction = NvMs[a]['corrections']\n",
    "\n",
    "    assert(len(bin_idx) == len(snapshot_pos))\n",
    "    #now lets get to spatial jackknife\n",
    "    N_DIVS = 4 #each axis is diided into N_DIVS parts so in total the box\n",
    "               #is divided into N_DIVS**3 boxes\n",
    "\n",
    "    #compute the size of each smaller cube\n",
    "    ϵ = vol*10**(-6)\n",
    "    cube_vol = (vol+ε) / N_DIVS**3 #need ϵ to properly handle halos directly on boundary \n",
    "    cube_size = np.cbrt(cube_vol)\n",
    "    rescale_factor = N_DIVS**3/(N_DIVS**3-1)\n",
    "\n",
    "    #compute the indices of the smaller cube that each point belongs to\n",
    "    cube_indices = (snapshot_pos / cube_size).astype(int)\n",
    "\n",
    "    #cube_indices has assignment of halo to 3d position of a voxel\n",
    "    #ravel_multi_index indexes the voxels in 3D with a single integer\n",
    "    cube_assignment = np.ravel_multi_index(cube_indices.T, (N_DIVS, N_DIVS, N_DIVS), order='F')\n",
    "\n",
    "    jackknife_data = []\n",
    "\n",
    "    for i in range(N_DIVS**3):\n",
    "        current_cube = np.where(cube_assignment == i)\n",
    "        curr_N = np.zeros_like(N)\n",
    "        for halo in bin_idx[current_cube]:\n",
    "            #bin_idx=1 corresponds to first bin \n",
    "            #bin_idx-1 = idx of bin\n",
    "            if(halo==0):\n",
    "                continue\n",
    "            curr_N[halo-1] += 1\n",
    "        #get the histogram if we left out this sub-cube\n",
    "        jackknife_data += [[a-b for (a,b) in zip(N, curr_N)]]\n",
    "\n",
    "    jackknife_mean = np.mean(jackknife_data, axis=0)\n",
    "\n",
    "    jackknife_data = np.array(jackknife_data) - jackknife_mean\n",
    "    jackknife_data *= rescale_factor\n",
    "    jackknife_covariance = np.cov(jackknife_data.T)\n",
    "    \n",
    "    jackknife[a] = [jackknife_data, jackknife_covariance]\n",
    "f_pos.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23801149",
   "metadata": {},
   "outputs": [],
   "source": [
    "jackknife_covs_fname = '/oak/stanford/orgs/kipac/users/delon/aemulusnu_massfunction/'+curr_run_fname.split('/')[-2]+'_jackknife_covs.pkl'\n",
    "jackknife_covs_f = open(jackknife_covs_fname, 'wb')\n",
    "pickle.dump(jackknife, jackknife_covs_f)\n",
    "jackknife_covs_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0627e24b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "massfunction",
   "language": "python",
   "name": "massfunction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
